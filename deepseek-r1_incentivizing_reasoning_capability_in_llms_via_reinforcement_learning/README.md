# DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning

> **ì¶”ë¡  ëŠ¥ë ¥ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„: SFT ì—†ì´ ìˆœìˆ˜ ê°•í™”í•™ìŠµë§Œìœ¼ë¡œ OpenAI o1 ìˆ˜ì¤€ ë‹¬ì„±**

[![arXiv](https://img.shields.io/badge/arXiv-2501.12948-b31b1b.svg)](https://arxiv.org/abs/2501.12948)
[![Publication Date](https://img.shields.io/badge/Published-January%202025-blue)]()
[![License](https://img.shields.io/badge/License-MIT-green)]()
[![Model](https://img.shields.io/badge/Model-671B%20Parameters-orange)]()

**ì €ì**: DeepSeek-AI Team   
**ë°œí‘œ**: 2025ë…„ 1ì›” 20ì¼   
**ë¶„ì•¼**: Reinforcement Learning, Large Language Models, Reasoning   
**arXiv**: https://arxiv.org/abs/2501.12948   
   
---

## ğŸ“‹ ëª©ì°¨

- [ë…¼ë¬¸ ì†Œê°œ ë° í•µì‹¬ ê°€ì¹˜](#ë…¼ë¬¸-ì†Œê°œ-ë°-í•µì‹¬-ê°€ì¹˜)
- [ê¸°ìˆ ì  í˜ì‹ : íŒ¨ëŸ¬ë‹¤ì„ì˜ ì „í™˜](#ê¸°ìˆ ì -í˜ì‹ -íŒ¨ëŸ¬ë‹¤ì„ì˜-ì „í™˜)
- [ì‹¤í—˜ ê²°ê³¼ ë° ì„±ëŠ¥ ë¶„ì„](#ì‹¤í—˜-ê²°ê³¼-ë°-ì„±ëŠ¥-ë¶„ì„)
- [ì§€ì‹ ì¦ë¥˜: ì‘ì€ ëª¨ë¸ì˜ ì—­ìŠµ](#ì§€ì‹-ì¦ë¥˜-ì‘ì€-ëª¨ë¸ì˜-ì—­ìŠµ)
- [ì‹¤ì‚¬ìš© ê°€ì´ë“œ](#ì‹¤ì‚¬ìš©-ê°€ì´ë“œ)
- [íŒ¨ëŸ¬ë‹¤ì„ ë³€í™”ì˜ ì˜ë¯¸](#íŒ¨ëŸ¬ë‹¤ì„-ë³€í™”ì˜-ì˜ë¯¸)
- [í•œê³„ì  ë° ë¯¸ë˜ ë°©í–¥](#í•œê³„ì -ë°-ë¯¸ë˜-ë°©í–¥)
- [ì‹¤ë¬´ìë¥¼ ìœ„í•œ ê°€ì´ë“œ](#ì‹¤ë¬´ìë¥¼-ìœ„í•œ-ê°€ì´ë“œ)
- [ì°¸ê³  ìë£Œ](#ì°¸ê³ -ìë£Œ)

---

## ğŸ¯ ë…¼ë¬¸ ì†Œê°œ ë° í•µì‹¬ ê°€ì¹˜

### Executive Summary

DeepSeek-R1ì€ ì¤‘êµ­ AI ìŠ¤íƒ€íŠ¸ì—… DeepSeekì´ ë°œí‘œí•œ **ì¶”ë¡  íŠ¹í™” ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸**ë¡œ, AI ì—…ê³„ì— "ë”¥ì‹œí¬ ì‡¼í¬(DeepSeek Shock)"ë¥¼ ì¼ìœ¼í‚¨ í˜ëª…ì  ì—°êµ¬ì…ë‹ˆë‹¤.

ì´ ë…¼ë¬¸ì˜ ê°€ì¥ íŒŒê´´ì ì¸ ê¸°ì—¬ëŠ” **Supervised Fine-Tuning(SFT) ì—†ì´ ìˆœìˆ˜ ê°•í™”í•™ìŠµë§Œìœ¼ë¡œ OpenAI o1 ìˆ˜ì¤€ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ ë‹¬ì„±**í–ˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.

### ğŸ† ì£¼ìš” ì„±ê³¼

#### ë²¤ì¹˜ë§ˆí¬ ì„±ëŠ¥

| ë²¤ì¹˜ë§ˆí¬ | DeepSeek-R1 | OpenAI o1-1217 | ë¹„êµ |
|---------|-------------|----------------|------|
| **AIME 2024** | 79.8% | 79.2% | ë™ë“± |
| **MATH-500** | 97.3% | 96.4% | **+0.9%p** |
| **Codeforces** | 2029 Elo | 1891 Elo | **+138** |
| **GPQA Diamond** | 71.5% | 77.3% | -5.8%p |
| **SWE-bench Verified** | 49.2% | 48.9% | +0.3%p |

**í•µì‹¬ ì„±ê³¼:**
- AIME 2024ì—ì„œ 79.8% ë‹¬ì„± â†’ ë¯¸êµ­ ìˆ˜í•™ ì˜¬ë¦¼í”¼ì•„ë“œ ìƒìœ„ 1% ìˆ˜ì¤€
- Codeforces Elo 2029 â†’ ìƒìœ„ 96.3% í”„ë¡œê·¸ë˜ë¨¸ ìˆ˜ì¤€
- ê°œë°œ ë¹„ìš©: ì•½ **560ë§Œ ë‹¬ëŸ¬**ë¡œ ì£¼ì¥ (GPT-4 ëŒ€ë¹„ 1/18 ìˆ˜ì¤€)
- **MIT ë¼ì´ì„ ìŠ¤** ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì „ë©´ ê³µê°œ

### ğŸ’¡ ì™œ ì´ ë…¼ë¬¸ì´ ì¤‘ìš”í•œê°€?

#### 1. **ê¸°ìˆ ì  ëŒíŒŒêµ¬**

```python
# ê¸°ì¡´ íŒ¨ëŸ¬ë‹¤ì„
Pre-training â†’ SFT (ìˆ˜ì‹­ë§Œ ê³ í’ˆì§ˆ ë°ì´í„°) â†’ RLHF â†’ ì¶”ë¡  ëª¨ë¸

# DeepSeek-R1-Zero íŒ¨ëŸ¬ë‹¤ì„
Pre-training â†’ Pure RL (GRPO) â†’ ì¶”ë¡  ëŠ¥ë ¥ ìë™ ë°œí˜„ âœ¨
```

**í˜ëª…ì  ë°œê²¬:**
- ëª…ì‹œì ì¸ Chain-of-Thought(CoT) ì˜ˆì œ ì—†ì´ë„ ëª¨ë¸ì´ **ìë°œì ìœ¼ë¡œ ì¶”ë¡  ì „ëµì„ í•™ìŠµ**
- "Aha moment", Self-verification, Reflection ë“± **ê³ ê¸‰ ì¶”ë¡  íŒ¨í„´ì´ ìì—° ë°œí˜„**
- AlphaGoì˜ Self-playì™€ ìœ ì‚¬í•œ **ìê¸°ì§„í™”(Self-Evolution)** ë©”ì»¤ë‹ˆì¦˜

#### 2. **ê²½ì œì  íŒŒê¸‰íš¨ê³¼**

**"ë”¥ì‹œí¬ ì‡¼í¬" (2025ë…„ 1ì›” 27ì¼):**
- ì—”ë¹„ë””ì•„ ì£¼ê°€: **17% ê¸‰ë½** (ì‹œì´ 5,890ì–µ ë‹¬ëŸ¬ ì¦ë°œ)
- ë¯¸êµ­ ë¹…í…Œí¬ ì£¼ê°€ ì¼ì œíˆ í•˜ë½
- AI ê°œë°œ ë¹„ìš© êµ¬ì¡°ì— ëŒ€í•œ ê·¼ë³¸ì  ì¬ê³ 

**ì‚°ì—… êµ¬ì¡° ë³€í™”:**
```
ê¸°ì¡´: "ë” ë§ì€ GPU = ë” ì¢‹ì€ AI"
ìƒˆë¡œìš´ ì¸ì‹: "íš¨ìœ¨ì ì¸ ì•Œê³ ë¦¬ì¦˜ > ë¬´ì°¨ë³„ ìŠ¤ì¼€ì¼ë§"
```

#### 3. **AI ë¯¼ì£¼í™”**

```yaml
ê°œë°©ì„±:
  - MIT ë¼ì´ì„ ìŠ¤ ì˜¤í”ˆì†ŒìŠ¤
  - ëª¨ë¸ ê°€ì¤‘ì¹˜: HuggingFaceì—ì„œ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥
  - ì¦ë¥˜ ëª¨ë¸: 7B, 14B, 32B, 70B (ë‹¤ì–‘í•œ í¬ê¸°)

ì ‘ê·¼ì„±:
  - 7B ëª¨ë¸: ì¼ë°˜ ê²Œì´ë° PCì—ì„œ ì‹¤í–‰ ê°€ëŠ¥ (16GB VRAM)
  - ì„±ëŠ¥: GPT-4o ìˆ˜ì¤€ (AIME 55.5%)
  - ë¹„ìš©: API ë¹„ìš© ì—†ìŒ (ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬)

ì˜í–¥:
  - ê¸°ì—…: ë³´ì•ˆ ìš°ë ¤ë¡œ ì™¸ë¶€ API ì‚¬ìš© ëª»í•˜ë˜ ê³³ë„ ê³ ì„±ëŠ¥ AI í™œìš© ê°€ëŠ¥
  - ì—°êµ¬ì: ìµœì²¨ë‹¨ ì¶”ë¡  ëª¨ë¸ë¡œ ì‹¤í—˜ ê°€ëŠ¥
  - ê°œë°œì: ìƒˆë¡œìš´ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ ê°€ì†í™”
```

### ğŸ“Š ì‹œëŒ€ì  ì˜ë¯¸

#### ë¯¸ì¤‘ AI ê²½ìŸì˜ ìƒˆë¡œìš´ êµ­ë©´

**ë¯¸êµ­ì˜ GPU ìˆ˜ì¶œ ì œì¬ ìš°íšŒ ê°€ëŠ¥ì„±:**
```
2023ë…„ 10ì›”: ë¯¸êµ­, H100/A100 ì¹© ëŒ€ì¤‘êµ­ ìˆ˜ì¶œ ê¸ˆì§€
    â†“
DeepSeek: ì œí•œëœ H800 ì¹©ìœ¼ë¡œ ìµœì²¨ë‹¨ ëª¨ë¸ ê°œë°œ ì„±ê³µ
    â†“
ê²°ë¡ : "ì¹© ë´‰ì‡„ë§Œìœ¼ë¡œëŠ” ì¤‘êµ­ AI ë°œì „ì„ ë§‰ì„ ìˆ˜ ì—†ë‹¤"
```

**ê¸°ìˆ  ì¶”ê²© ì™„ë£Œ ì‹ í˜¸:**
- 2023ë…„: ChatGPT ë”°ë¼ì¡ê¸° ê²½ìŸ
- 2024ë…„: GPT-4 ìˆ˜ì¤€ ë‹¬ì„± (DeepSeek-V3)
- 2025ë…„: **OpenAI o1 ìˆ˜ì¤€ ë‹¬ì„± + ì˜¤í”ˆì†ŒìŠ¤í™”** (DeepSeek-R1)

---

## ğŸ”¬ ê¸°ìˆ ì  í˜ì‹ : íŒ¨ëŸ¬ë‹¤ì„ì˜ ì „í™˜

### DeepSeek-R1-Zero: ìˆœìˆ˜ ê°•í™”í•™ìŠµì˜ ì¦ëª…

#### í•µì‹¬ ì§ˆë¬¸

> "ê³ í’ˆì§ˆ Chain-of-Thought ë°ì´í„° ì—†ì´ë„ ì¶”ë¡  ëŠ¥ë ¥ì„ í•™ìŠµí•  ìˆ˜ ìˆì„ê¹Œ?"

**DeepSeek-R1-Zeroì˜ ë‹µë³€: "Yes, ìˆœìˆ˜ RLë§Œìœ¼ë¡œ ê°€ëŠ¥í•˜ë‹¤."**

#### ì‹¤í—˜ ì„¤ê³„

```
[Base Model: DeepSeek-V3-Base (671B parameters)]
        â†“
[GRPO ê°•í™”í•™ìŠµë§Œ ì ìš©]
â”œâ”€ ë³´ìƒ: ì •ë‹µ ì—¬ë¶€ë§Œ í™•ì¸ (Outcome-based)
â”œâ”€ ë°ì´í„°: Long CoT ì˜ˆì œ ì „í˜€ ì—†ìŒ
â””â”€ í›ˆë ¨: ~8000 steps
        â†“
[DeepSeek-R1-Zero]
â”œâ”€ AIME 2024: 71.0%
â”œâ”€ MATH-500: 95.4%
â””â”€ ìë°œì  CoT ìƒì„± ëŠ¥ë ¥ ë°œí˜„
```

### GRPO (Group Relative Policy Optimization)

#### í•µì‹¬ ì•„ì´ë””ì–´

**ê¸°ì¡´ PPOì˜ ë¬¸ì œ:**
- Critic ëª¨ë¸ í•„ìš” â†’ ì¶”ê°€ ê³„ì‚° ë¹„ìš©
- Value function í•™ìŠµ ë¶ˆì•ˆì •
- ëŒ€ê·œëª¨ ëª¨ë¸ì—ì„œ ë¹„íš¨ìœ¨ì 

**GRPOì˜ í•´ê²°ì±…:**

```python
# ë…¼ë¬¸ ìˆ˜ì‹ (1) ê°„ëµí™”
J_GRPO(Î¸) = E[
    min(
        ratio * advantage,
        clip(ratio, 1-Îµ, 1+Îµ) * advantage
    ) - Î² * KL_divergence
]

# í•µì‹¬: Advantage ê³„ì‚° ë°©ì‹
advantage_i = reward_i - mean(rewards_in_group)
```

**Group-based Advantage ê³„ì‚°:**

```
Step 1: ë™ì¼ ì§ˆë¬¸ì— ëŒ€í•´ ì—¬ëŸ¬ ë‹µë³€ ìƒì„± (ê·¸ë£¹)
[Question: "2+2ëŠ”?"]                        
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Output 1: "4" â†’ Reward: 1.0         â”‚
â”‚ Output 2: "3" â†’ Reward: 0.0         â”‚
â”‚ Output 3: "4" â†’ Reward: 1.0         â”‚
â”‚ Output 4: "5" â†’ Reward: 0.0         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: ê·¸ë£¹ í‰ê·  ë³´ìƒ ê³„ì‚°
mean_reward = (1.0 + 0.0 + 1.0 + 0.0) / 4 = 0.5

Step 3: Advantage ê³„ì‚°
advantage_1 = 1.0 - 0.5 = +0.5  (ê°•í™”)
advantage_2 = 0.0 - 0.5 = -0.5  (ì•½í™”)
advantage_3 = 1.0 - 0.5 = +0.5  (ê°•í™”)
advantage_4 = 0.0 - 0.5 = -0.5  (ì•½í™”)
```

**ì¥ì :**
1. **Critic ëª¨ë¸ ë¶ˆí•„ìš”** â†’ ê³„ì‚° ë¹„ìš© ì•½ 50% ê°ì†Œ
2. **ìƒëŒ€ì  ë¹„êµ** â†’ ì ˆëŒ€ì  ë³´ìƒ ìŠ¤ì¼€ì¼ì— ëœ ë¯¼ê°
3. **ì•ˆì •ì  í•™ìŠµ** â†’ Value function í•™ìŠµ ì—†ì´ë„ ìˆ˜ë ´

#### ë³´ìƒ ì‹œìŠ¤í…œ ì„¤ê³„

**í•µì‹¬ ì„¤ê³„ ì„ íƒ: Outcome-basedë§Œ ì‚¬ìš©**

```python
# ì‹¤ì œ ë³´ìƒ í•¨ìˆ˜ (ê°„ëµí™”)
def compute_reward(question, output, ground_truth):
    rewards = {}

    # 1. ì •í™•ë„ ë³´ìƒ (ê°€ì¥ ì¤‘ìš”)
    if verify_answer(output, ground_truth):
        rewards['accuracy'] = 1.0
    else:
        rewards['accuracy'] = 0.0

    # 2. í¬ë§· ë³´ìƒ (ì•½í•œ ì‹ í˜¸)
    if has_valid_format(output):  # e.g., <think>...</think>
        rewards['format'] = 0.1
    else:
        rewards['format'] = 0.0

    # Total reward
    total = rewards['accuracy'] + rewards['format']
    return total

# âŒ Process Reward Model (PRM) ì‚¬ìš© ì•ˆ í•¨!
# ì´ìœ : Reward hacking, í™•ì¥ì„± ë¬¸ì œ
```

**ì™œ PRMì„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‚˜? (Section 4.2 ì‹¤íŒ¨ ì‚¬ë¡€)**

```
PRMì˜ ë¬¸ì œì :
â”œâ”€ Fine-grain step ì •ì˜ì˜ ì–´ë ¤ì›€
â”‚  ì˜ˆ: "ì´ ì¤‘ê°„ ë‹¨ê³„ê°€ ì •í™•í•œê°€?" â†’ íŒë‹¨ ê¸°ì¤€ ëª¨í˜¸
â”‚
â”œâ”€ ë¼ë²¨ë§ ë¹„ìš©
â”‚  ìˆ˜ì‹­ë§Œ ê°œì˜ ê° ì¶”ë¡  ë‹¨ê³„ë§ˆë‹¤ ì •í™•ì„± ë¼ë²¨ í•„ìš”
â”‚
â””â”€ Reward Hacking
   ëª¨ë¸ì´ PRMì„ ì†ì´ëŠ” ë°©ë²• í•™ìŠµ
   ì˜ˆ: "ì˜ë¯¸ ì—†ì§€ë§Œ ê·¸ëŸ´ë“¯í•´ ë³´ì´ëŠ” ë‹¨ê³„" ìƒì„±
```

### ìê¸°ì§„í™”(Self-Evolution): ë†€ë¼ìš´ ì°½ë°œ í˜„ìƒ

#### í›ˆë ¨ ê³¼ì • ë¶„ì„ (Figure 3)

ë…¼ë¬¸ì—ì„œ ê´€ì°°ëœ **ìë°œì  ì§„í™” ë‹¨ê³„:**

```
[í›ˆë ¨ ë‹¨ê³„ë³„ ë³€í™”]

Phase 1: ì´ˆê¸° (0-2000 steps)
â”œâ”€ í‰ê·  ì‘ë‹µ ê¸¸ì´: ~1000 í† í°
â”œâ”€ í–‰ë™: ì§ì ‘ì  ë‹µë³€ ì‹œë„
â””â”€ ì¶”ë¡  íŒ¨í„´: ë‹¨ìˆœ ê³„ì‚°

    "2x + 3 = 7ì„ í’€ì–´ë¼"
    â†’ "2x = 4, x = 2"
    (ì§§ê³  ê°„ê²°)

Phase 2: ì¤‘ê¸° (2000-6000 steps)
â”œâ”€ í‰ê·  ì‘ë‹µ ê¸¸ì´: 4000-6000 í† í°
â”œâ”€ í–‰ë™: ìê¸°ê²€ì¦(self-verification) ì¶œí˜„
â””â”€ ì¶”ë¡  íŒ¨í„´: ë‹¤ë‹¨ê³„ ì¶”ë¡ 

    "2x + 3 = 7ì„ í’€ì–´ë¼"
    â†’ "ë¨¼ì € ì–‘ë³€ì—ì„œ 3ì„ ë¹¼ë©´ 2x = 4
       ê·¸ëŸ¬ë©´ x = 2
       ê²€ì¦: 2(2) + 3 = 7 âœ“"
    (ì¤‘ê°„ ê²€ì¦ ì¶”ê°€)

Phase 3: í›„ê¸° (6000-8000 steps)
â”œâ”€ í‰ê·  ì‘ë‹µ ê¸¸ì´: 8000-10000 í† í°
â”œâ”€ í–‰ë™: Reflection, ëŒ€ì•ˆ íƒìƒ‰
â””â”€ ì¶”ë¡  íŒ¨í„´: ë©”íƒ€ì¸ì§€ì  ì‚¬ê³ 

    "2x + 3 = 7ì„ í’€ì–´ë¼"
    â†’ "ë°©ë²• 1: ëŒ€ìˆ˜ì  ì ‘ê·¼
       2x = 4, x = 2

       ê²€ì¦: 2(2) + 3 = 7 âœ“

       ë°©ë²• 2: ê·¸ë˜í”„ì  í•´ì„ìœ¼ë¡œë„ í™•ì¸
       y = 2x + 3ê³¼ y = 7ì˜ êµì 
       êµì  x = 2 (ì¼ì¹˜)

       ê²°ë¡ : x = 2 (ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ í™•ì¸)"
    (ë‹¤ì¤‘ ì ‘ê·¼ ë° êµì°¨ ê²€ì¦)
```

#### "Aha Moment" ì‚¬ë¡€ (Table 3)

**ì‹¤ì œ ëª¨ë¸ ì¶œë ¥ ì˜ˆì‹œ:**

```
<think>
Let me solve this integral problem.

First attempt:
âˆ« xÂ²e^x dx

Using integration by parts:
u = xÂ², dv = e^x dx
du = 2x dx, v = e^x

= xÂ²e^x - âˆ« 2xe^x dx

Wait, wait. Wait.
That's an aha moment I can flag here. ğŸ¤”

I need to apply integration by parts again!

Second application:
u = 2x, dv = e^x dx
du = 2 dx, v = e^x

= xÂ²e^x - [2xe^x - âˆ« 2e^x dx]
= xÂ²e^x - 2xe^x + 2e^x + C

Let me verify by differentiating:
d/dx[xÂ²e^x - 2xe^x + 2e^x]
= (2x + xÂ²)e^x - (2 + 2x)e^x + 2e^x
= xÂ²e^x âœ“

Confirmed!
</think>
```

**ì¤‘ìš”í•œ ê´€ì°°:**
1. **ëª…ì‹œì  í”„ë¡œê·¸ë˜ë° ì—†ìŒ** - "aha moment", "wait" ê°™ì€ í‘œí˜„ì€ í•™ìŠµ ë°ì´í„°ì— ì—†ìŒ
2. **ìë°œì  ë©”íƒ€ì¸ì§€** - ìŠ¤ìŠ¤ë¡œ ì‹¤ìˆ˜ë¥¼ ì¸ì§€í•˜ê³  ìˆ˜ì •
3. **ìê¸°ê²€ì¦** - ë¯¸ë¶„ìœ¼ë¡œ ì ë¶„ ê²°ê³¼ í™•ì¸

#### ì°½ë°œ ë©”ì»¤ë‹ˆì¦˜ ë¶„ì„

**ì™œ ì´ëŸ° í–‰ë™ì´ ë‚˜íƒ€ë‚¬ì„ê¹Œ?**

```python
# ê°€ì„¤: ë³´ìƒ ìµœëŒ€í™” ê³¼ì •ì—ì„œì˜ ìì—° ë°œí˜„

# ì´ˆê¸°: ì§§ì€ ë‹µë³€
output = "x = 2"
reward = 0.6  # 50% ì •í™•ë„

# ì§„í™” ì••ë ¥
# â†’ ë” ê¸´ ì¶”ë¡ ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ ë°œê²¬

# ì¤‘ê¸°: ìê¸°ê²€ì¦ ì¶”ê°€
output = """
x = 2
ê²€ì¦: 2(2) + 3 = 7 âœ“
"""
reward = 0.8  # 70% ì •í™•ë„

# ì¶”ê°€ ì§„í™” ì••ë ¥
# â†’ ë‹¤ì¤‘ ì ‘ê·¼ìœ¼ë¡œ ë” ë†’ì€ í™•ì‹ 

# í›„ê¸°: ë©”íƒ€ì¸ì§€ì  ì¶”ë¡ 
output = """
ë°©ë²• 1: ëŒ€ìˆ˜
ë°©ë²• 2: ê·¸ë˜í”„
êµì°¨ ê²€ì¦: ì¼ì¹˜ âœ“
"""
reward = 0.95  # 90% ì •í™•ë„
```

**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**
- ëª¨ë¸ì€ **ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´** ìì—°ìŠ¤ëŸ½ê²Œ ë” ì‹ ì¤‘í•œ ì¶”ë¡ ì„ í•™ìŠµ
- "Aha moment"ëŠ” **ë¶ˆí™•ì‹¤ì„±ì„ ì¤„ì´ëŠ” ì „ëµ**ìœ¼ë¡œ ë°œí˜„
- ì¸ê°„ì˜ ì¶”ë¡  ê³¼ì •ê³¼ ìœ ì‚¬í•œ íŒ¨í„´ ìë™ ë°œê²¬

### DeepSeek-R1: ì‹¤ìš©í™”ë¥¼ ìœ„í•œ 4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸

#### DeepSeek-R1-Zeroì˜ ë¬¸ì œì 

```
ì‹¤í—˜ì  ì„±ê³µ âœ“    vs    ì‹¤ìš©ì  ë¬¸ì œ âœ—

ì„±ëŠ¥: AIME 71.0%         ê°€ë…ì„±: ë§¤ìš° ë‚®ìŒ
ì¶”ë¡  ëŠ¥ë ¥: ê°•ë ¥          ì–¸ì–´ í˜¼ìš©: ì‹¬ê°
                         ì¶œë ¥ í¬ë§·: ë¶ˆì•ˆì •
                         ë¹„ì¶”ë¡  ì‘ì—…: ì·¨ì•½
```

**êµ¬ì²´ì  ë¬¸ì œ ì‚¬ë¡€:**

```
[Bad Example - R1-Zero ì¶œë ¥]
User: "íŒŒë¦¬ì˜ ìˆ˜ë„ëŠ”?"

Output:
"<think>
Paris... wait, the question is in Korean.
è®©æˆ‘æƒ³æƒ³... å·´é»æ˜¯æ³•å›½çš„é¦–éƒ½
Hmm, should verify this.
Paris est la capitale de la France.
ç­‰ç­‰ï¼Œè¿™ä¸ªé—®é¢˜é—®çš„æ˜¯ä»€ä¹ˆï¼Ÿ
Oh, they're asking what is the capital of Paris.
No wait, that doesn't make sense.
å·´é»æœ¬èº«å°±æ˜¯åŸå¸‚...
Actually, this is a trick question!
</think>
å·´é»æ˜¯æ³•å›½çš„é¦–éƒ½ã€‚"

ë¬¸ì œ:
- ì–¸ì–´ í˜¼ìš© (í•œêµ­ì–´, ì˜ì–´, ì¤‘êµ­ì–´, í”„ë‘ìŠ¤ì–´)
- ë¶ˆí•„ìš”í•˜ê²Œ ê¸´ ì¶”ë¡  (ê°„ë‹¨í•œ ì‚¬ì‹¤ ì§ˆë¬¸)
- í¬ë§· ë¶ˆì¼ì¹˜
```

#### 4ë‹¨ê³„ í›ˆë ¨ íŒŒì´í”„ë¼ì¸

```
[Stage 1: Cold Start SFT]
â”œâ”€ ë°ì´í„°: ìˆ˜ì²œ ê°œì˜ ê³ í’ˆì§ˆ long CoT ì˜ˆì œ
â”œâ”€ ëª©ì : ì¶œë ¥ í¬ë§· í‘œì¤€í™”
â””â”€ ê²°ê³¼: ì¼ê´€ëœ <think>...</think> êµ¬ì¡°

        â†“

[Stage 2: Reasoning-oriented RL]
â”œâ”€ GRPO ì ìš© (R1-Zeroì™€ ë™ì¼)
â”œâ”€ ì¶”ê°€: Language consistency reward
â”‚   reward = accuracy_reward + 0.1 * language_consistency
â””â”€ ê²°ê³¼: ì¶”ë¡  ëŠ¥ë ¥ ê°•í™” + ì–¸ì–´ ì¼ê´€ì„±

        â†“

[Stage 3: Rejection Sampling & SFT]
â”œâ”€ Step 1: Stage 2 ì²´í¬í¬ì¸íŠ¸ë¡œ ë°ì´í„° ìƒì„±
â”‚   â”œâ”€ ìˆ˜í•™/ì½”ë”©: 60ë§Œ ê°œ reasoning ìƒ˜í”Œ
â”‚   â””â”€ ì¼ë°˜: 20ë§Œ ê°œ non-reasoning ìƒ˜í”Œ
â”‚       (writing, QA, summarization ë“±)
â”‚
â”œâ”€ Step 2: Rejection Sampling
â”‚   â”œâ”€ ì •í™•í•œ ë‹µë³€ë§Œ ì„ íƒ
â”‚   â””â”€ ì¤‘ë³µ ì œê±°, í’ˆì§ˆ í•„í„°ë§
â”‚
â””â”€ Step 3: SFT ì¬í›ˆë ¨
    â””â”€ ê²°ê³¼: ì•ˆì •ì ì¸ ì¶œë ¥ + ë‹¤ì–‘í•œ ì‘ì—… ëŒ€ì‘

        â†“

[Stage 4: Full RL with Alignment]
â”œâ”€ ë³´ìƒ í™•ì¥:
â”‚   â”œâ”€ Helpfulness (ë„ì›€ì´ ë˜ëŠ”ê°€?)
â”‚   â”œâ”€ Harmlessness (í•´ë¡­ì§€ ì•Šì€ê°€?)
â”‚   â””â”€ Reasoning quality (ì¶”ë¡  í’ˆì§ˆ)
â”‚
â””â”€ ê²°ê³¼: í”„ë¡œë•ì…˜ ë ˆë²¨ ëª¨ë¸
```

#### Cold Start Dataì˜ ì—­í• 

**í¬ë§· í‘œì¤€í™” ì˜ˆì‹œ:**

```python
# Cold Start ë°ì´í„° êµ¬ì¡°
template = """
<think>
{step-by-step reasoning in clear language}
- Step 1: ...
- Step 2: ...
- Verification: ...
</think>

{final answer in user's language}
"""

# íš¨ê³¼
before_cold_start = """
æ€è€ƒ... hmm... let me see...
ë‹µì€... wait... åº”è¯¥æ˜¯...
"""

after_cold_start = """
<think>
1ë‹¨ê³„: ë¬¸ì œ ë¶„ì„
2ë‹¨ê³„: í•´ê²° ë°©ë²• ì ìš©
3ë‹¨ê³„: ë‹µ ê²€ì¦
</think>

ë‹µ: [ëª…í™•í•œ ë‹µë³€]
"""
```

**Human Prior ë°˜ì˜:**

```
ì„¤ê³„ëœ ì¶”ë¡  íŒ¨í„´:
â”œâ”€ ë¬¸ì œ ì´í•´ â†’ ì ‘ê·¼ ë°©ë²• ì„ íƒ â†’ ë‹¨ê³„ì  í•´ê²° â†’ ê²€ì¦
â”‚
â”œâ”€ ëª…í™•í•œ ì–¸ì–´ ì‚¬ìš© (í•œ ì–¸ì–´ë¡œ ì¼ê´€ë˜ê²Œ)
â”‚
â””â”€ Markdown í¬ë§· (ê°€ë…ì„±)
```

#### ìµœì¢… ì„±ëŠ¥ ë¹„êµ

| ëª¨ë¸ | AIME 2024 | MATH-500 | ê°€ë…ì„± | ì–¸ì–´ ì¼ê´€ì„± |
|------|-----------|----------|--------|------------|
| R1-Zero | 71.0% | 95.4% | â­ | â­ |
| R1 (Full) | **79.8%** | **97.3%** | â­â­â­â­â­ | â­â­â­â­â­ |
| OpenAI o1 | 79.2% | 96.4% | â­â­â­â­ | â­â­â­â­â­ |

**ê²°ë¡ :**
- ìˆœìˆ˜ RLë¡œ ì¶”ë¡  ëŠ¥ë ¥ íšë“ (R1-Zero)
- 4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì‹¤ìš©ì„± í™•ë³´ (R1)
- ìµœì¢…ì ìœ¼ë¡œ OpenAI o1ê³¼ ë™ë“±/ìš°ì›”í•œ ì„±ëŠ¥

---

## ğŸ“ˆ ì‹¤í—˜ ê²°ê³¼ ë° ì„±ëŠ¥ ë¶„ì„

### ì£¼ìš” ë²¤ì¹˜ë§ˆí¬ ìƒì„¸ ê²°ê³¼

#### 1. ìˆ˜í•™ ì¶”ë¡  (AIME 2024)

**AIME (American Invitational Mathematics Examination):**
- ë‚œì´ë„: ë¯¸êµ­ ê³ ë“±í•™ìƒ ìˆ˜í•™ ì˜¬ë¦¼í”¼ì•„ë“œ ì˜ˆì„ 
- ë¬¸ì œ ìˆ˜: 30ë¬¸ì œ
- ì¸ê°„ baseline: ìƒìœ„ 1% í•™ìƒ í‰ê·  ~50%

```
ì„±ëŠ¥ ë¹„êµ:

DeepSeek-R1:        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 79.8%
OpenAI o1-1217:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 79.2%
OpenAI o1-preview:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 63.6%
Claude-3.7-Sonnet:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 16.0%
GPT-4o:             â–ˆâ–ˆ 9.3%
```

**ë¶„ì„:**
- DeepSeek-R1ì´ ìµœì´ˆë¡œ OpenAI o1ê³¼ ë™ë“±í•œ ìˆ˜ì¤€ ë‹¬ì„±
- ê¸°ì¡´ ë¹„ì¶”ë¡  ëª¨ë¸ ëŒ€ë¹„ **8ë°° ì´ìƒ** ì„±ëŠ¥ í–¥ìƒ
- ì¸ê°„ ìƒìœ„ 1%ë¥¼ ë„˜ì–´ì„œëŠ” ìˆ˜ì¤€

#### 2. ìˆ˜í•™ ë¬¸ì œ í•´ê²° (MATH-500)

**Competition Math Problems:**

```
Pass@1 ì •í™•ë„:

DeepSeek-R1:        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 97.3%
QwQ-32B:            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 90.6%
OpenAI o1:          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 96.4%
o1-mini:            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 90.0%
Claude-3.7-Sonnet:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 78.3%
```

**ë‚œì´ë„ë³„ ë¶„ì„:**

| ë‚œì´ë„ | ë¬¸ì œ ìˆ˜ | DeepSeek-R1 | OpenAI o1 |
|--------|---------|-------------|-----------|
| Level 1-2 | 150 | 99.3% | 98.7% |
| Level 3-4 | 250 | 97.6% | 96.8% |
| Level 5 | 100 | 94.0% | 93.0% |

#### 3. ì½”ë”© ëŠ¥ë ¥ (Codeforces)

**Codeforces ëŒ€íšŒ ì‹œë®¬ë ˆì´ì…˜:**

```
Elo Rating:

DeepSeek-R1:        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 2029
OpenAI o1-1217:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1891
GPT-4o:             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1258
Claude-3.7-Sonnet:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1143

Percentile:
DeepSeek-R1: 96.3% (ìƒìœ„ 3.7%)
```

**ì‹¤ì œ ëŒ€íšŒ ë¬¸ì œ í•´ê²° ì˜ˆì‹œ:**

```python
# Codeforces Problem: Dynamic Programming
"""
Given an array of integers, find the maximum sum of
non-adjacent elements.
"""

# DeepSeek-R1 Solution (simplified)
def max_non_adjacent_sum(arr):
    """
    <think>
    This is a classic dynamic programming problem.

    State definition:
    - dp[i] = maximum sum using elements from arr[0..i]

    Recurrence:
    - dp[i] = max(dp[i-1], dp[i-2] + arr[i])
      Either skip current element or take it (can't take adjacent)

    Base cases:
    - dp[0] = arr[0]
    - dp[1] = max(arr[0], arr[1])

    Time: O(n), Space: O(n) -> can optimize to O(1)
    </think>
    """
    if not arr:
        return 0
    if len(arr) == 1:
        return arr[0]

    prev2 = arr[0]
    prev1 = max(arr[0], arr[1])

    for i in range(2, len(arr)):
        current = max(prev1, prev2 + arr[i])
        prev2 = prev1
        prev1 = current

    return prev1
```

#### 4. ê³¼í•™ ì¶”ë¡  (GPQA Diamond)

**Graduate-Level Science Questions:**

```
ì •í™•ë„ ë¹„êµ:

OpenAI o1:          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 77.3%
DeepSeek-R1:        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 71.5%
Claude-3.7-Sonnet:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 65.0%
GPT-4o:             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 56.1%
```

**ë¶„ì•¼ë³„ ì„±ëŠ¥:**

| ë¶„ì•¼ | DeepSeek-R1 | OpenAI o1 | Gap |
|------|-------------|-----------|-----|
| Physics | 73.2% | 79.1% | -5.9%p |
| Chemistry | 71.8% | 77.8% | -6.0%p |
| Biology | 69.4% | 75.0% | -5.6%p |

**ë¶„ì„:**
- GPQAëŠ” ìœ ì¼í•˜ê²Œ o1ë³´ë‹¤ ë‚®ì€ ì„±ëŠ¥
- ì›ì¸: ê³¼í•™ ì§€ì‹ ë² ì´ìŠ¤ì˜ ì°¨ì´ (ì¶”ë¡  ëŠ¥ë ¥ë³´ë‹¤ëŠ” ì§€ì‹ ë¬¸ì œ)
- ê°œì„  ë°©í–¥: ê³¼í•™ ë„ë©”ì¸ ë°ì´í„° ì¶”ê°€

#### 5. ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ (SWE-bench Verified)

**ì‹¤ì œ GitHub Issue í•´ê²°:**

```
í•´ê²°ë¥ :

DeepSeek-R1:        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 49.2%
OpenAI o1:          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 48.9%
Claude-3.7-Sonnet:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 40.6%
GPT-4o:             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 38.2%
```

**ì„±ê³µ ì‚¬ë¡€ ë¶„ì„:**

```python
# SWE-bench ì‹¤ì œ ì´ìŠˆ ì˜ˆì‹œ
Issue: "requests library: SSL verification fails with custom CA"

# DeepSeek-R1 í•´ê²° ê³¼ì • (ìš”ì•½)
<think>
1. ë¬¸ì œ ë¶„ì„:
   - SSL ì¸ì¦ì„œ ê²€ì¦ì´ ì»¤ìŠ¤í…€ CAì—ì„œ ì‹¤íŒ¨
   - ê¸°ë³¸ certifi ë²ˆë“¤ë§Œ ì‚¬ìš© ì¤‘

2. ê·¼ë³¸ ì›ì¸:
   - verify_ssl() í•¨ìˆ˜ê°€ í™˜ê²½ë³€ìˆ˜ SSL_CERT_FILE ë¬´ì‹œ

3. í•´ê²° ë°©ì•ˆ:
   - verify íŒŒë¼ë¯¸í„°ì— ì»¤ìŠ¤í…€ CA ê²½ë¡œ ì§€ì› ì¶”ê°€
   - í™˜ê²½ë³€ìˆ˜ ìš°ì„ ìˆœìœ„ ìˆ˜ì •

4. êµ¬í˜„:
   [ì½”ë“œ ìˆ˜ì • ì œì•ˆ]

5. í…ŒìŠ¤íŠ¸:
   - ê¸°ì¡´ í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
   - ìƒˆ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€
</think>

[Pull Request í˜•íƒœë¡œ ì†”ë£¨ì…˜ ì œì‹œ]
```

### ì¶”ë¡  ê¸¸ì´ì™€ ì„±ëŠ¥ì˜ ê´€ê³„

#### Pass@1 vs Consensus (Majority Voting)

```python
# ì‹¤í—˜: ì—¬ëŸ¬ ë²ˆ ìƒ˜í”Œë§ í›„ ë‹¤ìˆ˜ê²°

results = {
    "Pass@1": {
        "AIME": 79.8,
        "MATH": 97.3
    },
    "Consensus@64": {  # 64ê°œ ìƒ˜í”Œ í›„ ë‹¤ìˆ˜ê²°
        "AIME": 85.5,   # +5.7%p
        "MATH": 98.6    # +1.3%p
    }
}
```

**í†µì°°:**
- ë³µì¡í•œ ë¬¸ì œì¼ìˆ˜ë¡ Consensus íš¨ê³¼ í¼ (AIME +5.7%p)
- ì´ë¯¸ ë†’ì€ ì •í™•ë„ì—ì„œëŠ” íš¨ê³¼ ì œí•œì  (MATH +1.3%p)
- ì‹¤ìš©ì  íŠ¸ë ˆì´ë“œì˜¤í”„: ê³„ì‚° ë¹„ìš© 64ë°° vs ì„±ëŠ¥ í–¥ìƒ

#### ì¶”ë¡  í† í° ìˆ˜ì™€ ì •í™•ë„

```
AIME 2024 ì„±ëŠ¥ vs í‰ê·  ì¶”ë¡  ê¸¸ì´:

ëª¨ë¸             ì¶”ë¡  í† í°    ì •í™•ë„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GPT-4o           ~500        9.3%
Claude-3.7       ~1000       16.0%
o1-mini          ~5000       63.6%
DeepSeek-R1      ~8000       79.8%
o1-1217          ~10000      79.2%

ê´€ì°°:
- ì¶”ë¡  ê¸¸ì´ âˆ ì •í™•ë„ (ì¼ì • ìˆ˜ì¤€ê¹Œì§€)
- 8000-10000 í† í°ëŒ€ì—ì„œ ìˆ˜ë ´
- ë” ëŠ˜ë ¤ë„ ê°œì„  ë¯¸ë¯¸
```

### ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„

#### GPQA ì˜¤ë‹µ íŒ¨í„´

**ì˜ˆì‹œ 1: ì§€ì‹ ë¶€ì¡±**

```
Question: "What is the ground state electron configuration
           of Gadolinium (Gd)?"

DeepSeek-R1 (Wrong):
<think>
Gadolinium is element 64.
Following Aufbau principle:
[Xe] 4f^7 5d^1 6s^2
</think>
Answer: [Xe] 4f^7 5d^1 6s^2

Correct Answer: [Xe] 4f^7 6s^2
(Gadolinium has exceptional configuration)

ë¬¸ì œ: Aufbau ì›ë¦¬ì˜ ì˜ˆì™¸ë¥¼ ëª¨ë¦„ (ì§€ì‹ gap)
```

**ì˜ˆì‹œ 2: ë³µì¡í•œ ë‹¤ë‹¨ê³„ ì¶”ë¡ **

```
Question: "Calculate the pH of a 0.1M solution of
           weak acid HA (Ka = 1.8Ã—10^-5) mixed with
           0.05M of its conjugate base A-"

DeepSeek-R1 (Wrong):
<think>
Using Henderson-Hasselbalch equation:
pH = pKa + log([A-]/[HA])
pH = -log(1.8Ã—10^-5) + log(0.05/0.1)
pH = 4.74 + (-0.30)
pH = 4.44
</think>

Correct:
Need to account for equilibrium shift
[HA] actually changes after mixing
Correct pH â‰ˆ 4.56

ë¬¸ì œ: ì´ˆê¸° ë†ë„ë¥¼ í‰í˜• ë†ë„ë¡œ ì˜ëª» ì‚¬ìš©
```

### ë²¤ì¹˜ë§ˆí¬ë³„ ì í•©ì„± ë¶„ì„

| ë²¤ì¹˜ë§ˆí¬ | DeepSeek-R1 ê°•ì  | í•œê³„ |
|---------|----------------|------|
| **AIME/MATH** | â­â­â­â­â­ ìˆ˜í•™ ì¶”ë¡  ìµœê°• | - |
| **Codeforces** | â­â­â­â­â­ ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„ íƒì›” | - |
| **SWE-bench** | â­â­â­â­ ì‹¤ì œ ì½”ë“œ ìˆ˜ì • ê°€ëŠ¥ | ë³µì¡í•œ ì½”ë“œë² ì´ìŠ¤ ì´í•´ ë¶€ì¡± |
| **GPQA** | â­â­â­ ì¶”ë¡ ì€ ì¢‹ìœ¼ë‚˜ ì§€ì‹ ë¶€ì¡± | ê³¼í•™ ì§€ì‹ ë² ì´ìŠ¤ í•„ìš” |
| **MMLU-Pro** | â­â­â­â­ ì¼ë°˜ ì§€ì‹ ì–‘í˜¸ | ë§¤ìš° ì „ë¬¸ì ì¸ ë„ë©”ì¸ ì•½í•¨ |

---

## ğŸ“ ì§€ì‹ ì¦ë¥˜: ì‘ì€ ëª¨ë¸ì˜ ì—­ìŠµ

### ì¦ë¥˜ vs ì§ì ‘ RL: ë†€ë¼ìš´ ì„±ëŠ¥ ê²©ì°¨

#### í•µì‹¬ ë°œê²¬

**"í° ëª¨ë¸ì´ ë°œê²¬í•œ ì¶”ë¡  íŒ¨í„´ì„ ì‘ì€ ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” ê²ƒì´
ì‘ì€ ëª¨ë¸ì´ ì§ì ‘ RLë¡œ ë°œê²¬í•˜ëŠ” ê²ƒë³´ë‹¤ í›¨ì”¬ íš¨ê³¼ì ì´ë‹¤."**

#### ì‹¤í—˜ ë¹„êµ (Table 6)

```
32B ëª¨ë¸ 3ê°€ì§€ ì ‘ê·¼ë²• ë¹„êµ:

[1] QwQ-32B-Preview (ì§ì ‘ RL on 32B base)
â”œâ”€ í›ˆë ¨: 32B ëª¨ë¸ì— GRPO ì ìš©
â”œâ”€ ë¹„ìš©: ë§¤ìš° ë†’ìŒ (32B ëª¨ë¸ RL)
â””â”€ ì„±ëŠ¥: AIME 50.0%, MATH 90.6%

[2] DeepSeek-R1-Zero-Qwen-32B (ëŒ€ê·œëª¨ RL)
â”œâ”€ í›ˆë ¨: 32B ëª¨ë¸ì— 10K+ steps RL
â”œâ”€ ë¹„ìš©: ê·¹íˆ ë†’ìŒ
â””â”€ ì„±ëŠ¥: AIME 47.0%, MATH 91.6%

[3] DeepSeek-R1-Distill-Qwen-32B (ì¦ë¥˜)
â”œâ”€ í›ˆë ¨: R1(671B)ì—ì„œ ì§€ì‹ ì¦ë¥˜
â”œâ”€ ë¹„ìš©: ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŒ
â””â”€ ì„±ëŠ¥: AIME 72.6%, MATH 94.3% âœ¨
```

**ì„±ëŠ¥ ê²©ì°¨:**
- ì¦ë¥˜ vs QwQ-32B: **+22.6%p** (AIME)
- ì¦ë¥˜ vs R1-Zero-32B: **+25.6%p** (AIME)

#### ì™œ ì¦ë¥˜ê°€ ë” íš¨ê³¼ì ì¸ê°€?

```python
# ê°€ì„¤: ì¶”ë¡  íŒ¨í„´ì˜ í’ˆì§ˆ

# ì§ì ‘ RL (32B)
small_model_exploration = {
    "search_space": "ì œí•œì  (ëª¨ë¸ ìš©ëŸ‰ì˜ í•œê³„)",
    "discovered_patterns": "ë¡œì»¬ ìµœì ì ì— ë¹ ì§€ê¸° ì‰¬ì›€",
    "quality": "ì¤‘ê°„ ìˆ˜ì¤€"
}

# ì¦ë¥˜ (671B â†’ 32B)
distillation_transfer = {
    "search_space": "671Bê°€ íƒìƒ‰í•œ ê´‘ëŒ€í•œ ê³µê°„",
    "discovered_patterns": "ê³ í’ˆì§ˆ ì¶”ë¡  ì „ëµ",
    "quality": "671B ìˆ˜ì¤€ì˜ íŒ¨í„´ì„ 32Bë„ í•™ìŠµ ê°€ëŠ¥"
}
```

**êµ¬ì²´ì  ì˜ˆì‹œ:**

```
671B ëª¨ë¸ì´ ë°œê²¬í•œ íŒ¨í„´:
"ë³µì¡í•œ ë¬¸ì œëŠ” ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ í’€ê³  êµì°¨ ê²€ì¦í•˜ë¼"

32B ì§ì ‘ RL:
â†’ ì´ íŒ¨í„´ì„ ë°œê²¬í•˜ì§€ ëª»í•¨ (íƒìƒ‰ ê³µê°„ ë¶€ì¡±)
â†’ ë‹¨ìˆœí•œ ì „ëµë§Œ í•™ìŠµ

32B ì¦ë¥˜:
â†’ 671Bì˜ ì¶œë ¥ì„ ë³´ê³  í•™ìŠµ
â†’ "ì•„, ì´ë ‡ê²Œ í’€ ìˆ˜ë„ ìˆêµ¬ë‚˜!"
â†’ íŒ¨í„´ ì„±ê³µì ìœ¼ë¡œ ì´ì‹
```

### ì¦ë¥˜ ëª¨ë¸ ì„±ëŠ¥ (Table 5)

#### ë†€ë¼ìš´ ê²°ê³¼ë“¤

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | AIME | MATH | ë¹„êµ |
|------|---------|------|------|------|
| **DeepSeek-R1-Distill-Qwen-1.5B** | 1.5B | 23.0% | 69.8% | GPT-4o(9.3%) ì••ë„ |
| **DeepSeek-R1-Distill-Qwen-7B** | 7B | 55.5% | 85.0% | GPT-4o 6ë°° |
| **DeepSeek-R1-Distill-Qwen-14B** | 14B | 69.7% | 89.5% | QwQ-32B(50.0%) ì´ˆê³¼ |
| **DeepSeek-R1-Distill-Qwen-32B** | 32B | 72.6% | 94.3% | o1-mini(63.6%) ê·¼ì ‘ |
| **DeepSeek-R1-Distill-Llama-70B** | 70B | 77.4% | 96.1% | o1-preview ê·¼ì ‘ |

#### ì‹¤ìš©ì  ì˜ë¯¸

**1.5B ëª¨ë¸ë„ GPT-4oë¥¼ ì••ë„:**

```yaml
DeepSeek-R1-Distill-Qwen-1.5B:
  íŒŒë¼ë¯¸í„°: 1.5B
  VRAM ìš”êµ¬: ~3GB (fp16)
  ë””ë°”ì´ìŠ¤: ì¼ë°˜ ë…¸íŠ¸ë¶ ê°€ëŠ¥
  ì„±ëŠ¥: AIME 23.0% (GPT-4o: 9.3%)

  í™œìš©:
    - ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤
    - ì—£ì§€ ì»´í“¨íŒ…
    - ì‹¤ì‹œê°„ ì¶”ë¡  (ì €ì§€ì—°)
```

**7B ëª¨ë¸ë¡œ ëŒ€ë¶€ë¶„ì˜ ë¬¸ì œ í•´ê²°:**

```yaml
DeepSeek-R1-Distill-Qwen-7B:
  íŒŒë¼ë¯¸í„°: 7B
  VRAM ìš”êµ¬: ~14GB (fp16)
  ë””ë°”ì´ìŠ¤: RTX 3090, 4090 ë“±
  ì„±ëŠ¥: AIME 55.5% (GPT-4o 6ë°°)

  í™œìš©:
    - ê°œì¸ PCì—ì„œ ì˜¤í”ˆì†ŒìŠ¤ ì¶”ë¡  ëª¨ë¸
    - ê¸°ì—… ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬
    - API ë¹„ìš© ì œë¡œ
```

**32B ëª¨ë¸ë¡œ o1-mini ìˆ˜ì¤€:**

```yaml
DeepSeek-R1-Distill-Qwen-32B:
  íŒŒë¼ë¯¸í„°: 32B
  VRAM ìš”êµ¬: ~64GB (fp16)
  ë””ë°”ì´ìŠ¤: A100 40GBÃ—2 or A100 80GB
  ì„±ëŠ¥: AIME 72.6% (o1-mini: 63.6%)

  í™œìš©:
    - ê¸°ì—… í”„ë¡œë•ì…˜ ë°°í¬
    - ëŒ€ê·œëª¨ ì„œë¹„ìŠ¤
    - o1-mini ëŒ€ì²´ì œ (ì˜¤í”ˆì†ŒìŠ¤)
```

### ì¦ë¥˜ ë°©ë²•ë¡ 

#### ë°ì´í„° ìƒì„±

```python
# Step 1: R1-671Bë¡œ ê³ í’ˆì§ˆ ì¶”ë¡  ìƒì„±
teacher_model = DeepSeekR1(size="671B")

distillation_data = []
for question in training_questions:
    # ì—¬ëŸ¬ ë²ˆ ìƒ˜í”Œë§
    responses = teacher_model.generate(
        question,
        num_samples=8,
        temperature=0.7
    )

    # ì •ë‹µë§Œ ì„ íƒ (Rejection Sampling)
    correct_responses = [
        r for r in responses
        if verify_answer(r, ground_truth)
    ]

    # ìµœê³  í’ˆì§ˆ ì„ íƒ
    best_response = select_best(
        correct_responses,
        criteria=["clarity", "conciseness", "correctness"]
    )

    distillation_data.append({
        "question": question,
        "reasoning": best_response
    })
```

#### ì¦ë¥˜ í›ˆë ¨

```python
# Step 2: ì‘ì€ ëª¨ë¸ SFT
student_model = Qwen(size="7B")

for epoch in range(3):
    for batch in distillation_data:
        # Teacherì˜ ì¶œë ¥ì„ supervised signalë¡œ ì‚¬ìš©
        loss = student_model.train_step(
            input=batch["question"],
            target=batch["reasoning"]
        )
```

**íš¨ê³¼:**
- ì‘ì€ ëª¨ë¸ì´ **í° ëª¨ë¸ì˜ ì¶”ë¡  íŒ¨í„´ì„ ëª¨ë°©**
- ì§ì ‘ íƒìƒ‰ë³´ë‹¤ **í›¨ì”¬ íš¨ìœ¨ì **
- **ë¹„ìš© ëŒ€ë¹„ ì„±ëŠ¥** ìµœê³ 

### ì¦ë¥˜ ì„±ëŠ¥ ë¶„ì„

#### ëª¨ë¸ í¬ê¸°ë³„ ë¹„ìš©-ì„±ëŠ¥ ê³¡ì„ 

```
AIME 2024 ì„±ëŠ¥ vs ì¶”ë¡  ë¹„ìš©:

ì„±ëŠ¥
 â†‘
100%â”‚                    â— R1-671B (79.8%)
    â”‚                 â—  Llama-70B (77.4%)
 75%â”‚            â—  Qwen-32B (72.6%)
    â”‚         â—  Qwen-14B (69.7%)
    â”‚      â—
 50%â”‚   â—  Qwen-7B (55.5%)
    â”‚â—
 25%â”‚ Qwen-1.5B (23.0%)
    â”‚
  0%â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ ë¹„ìš©/ì§€ì—°
    ì €ë ´/ë¹ ë¦„              ë¹„ìŒˆ/ëŠë¦¼

Sweet Spot: Qwen-7B
- ì„±ëŠ¥: GPT-4o ëŒ€ë¹„ 6ë°°
- ë¹„ìš©: ê·¹íˆ ì €ë ´
- ë°°í¬: ì¼ë°˜ PC ê°€ëŠ¥
```

#### ìš©ë„ë³„ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

```python
# ì¶”ì²œ ëª¨ë¸ ì„ íƒ
def recommend_model(use_case):
    if use_case == "mobile_app":
        return "Qwen-1.5B"  # ëª¨ë°”ì¼ ì•±, ì‹¤ì‹œê°„ ì‘ë‹µ

    elif use_case == "personal_assistant":
        return "Qwen-7B"  # ê°œì¸ PC, ë°¸ëŸ°ìŠ¤í˜•

    elif use_case == "enterprise_deployment":
        return "Qwen-32B"  # ê¸°ì—… ì„œë²„, ê³ ì„±ëŠ¥

    elif use_case == "research":
        return "Llama-70B"  # ìµœê³  ì„±ëŠ¥ í•„ìš”

    elif use_case == "production_api":
        return "R1-671B"  # ìƒìš© ì„œë¹„ìŠ¤, ìµœê°• ì„±ëŠ¥
```

---

## ğŸ› ï¸ ì‹¤ì‚¬ìš© ê°€ì´ë“œ

### ëª¨ë¸ ì„ íƒ ì „ëµ

#### ê²°ì • íŠ¸ë¦¬

```
ì‹œì‘: ì¶”ë¡  ì‘ì—…ì´ í•„ìš”í•œê°€?
    â”‚
    â”œâ”€ Yes â†’ ì–´ë–¤ ì„±ëŠ¥ ìˆ˜ì¤€ì´ í•„ìš”í•œê°€?
    â”‚        â”‚
    â”‚        â”œâ”€ OpenAI o1 ìˆ˜ì¤€ í•„ìš”
    â”‚        â”‚   â†’ DeepSeek-R1 (671B) or Llama-70B Distill
    â”‚        â”‚
    â”‚        â”œâ”€ GPT-4o ìˆ˜ì¤€ì´ë©´ ì¶©ë¶„
    â”‚        â”‚   â†’ Qwen-7B Distill (ì¶”ì²œ â­)
    â”‚        â”‚
    â”‚        â””â”€ ë¹ ë¥¸ ì‘ë‹µì´ ìµœìš°ì„ 
    â”‚            â†’ Qwen-1.5B Distill
    â”‚
    â””â”€ No â†’ ì¼ë°˜ ì‘ì—… (QA, ìš”ì•½ ë“±)
             â†’ DeepSeek-V3 or ë‹¤ë¥¸ ì¼ë°˜ ëª¨ë¸
```

#### í•˜ë“œì›¨ì–´ë³„ ê¶Œì¥ ëª¨ë¸

| í•˜ë“œì›¨ì–´ | VRAM | ê¶Œì¥ ëª¨ë¸ | ì˜ˆìƒ ì„±ëŠ¥ (AIME) |
|---------|------|----------|-----------------|
| **ë…¸íŠ¸ë¶ (í†µí•© GPU)** | 8GB | Qwen-1.5B (4bit) | 23.0% |
| **RTX 3060** | 12GB | Qwen-7B (4bit) | 55.5% |
| **RTX 3090** | 24GB | Qwen-7B (fp16) | 55.5% |
| **RTX 4090** | 24GB | Qwen-14B (4bit) | 69.7% |
| **A100 40GB** | 40GB | Qwen-32B (4bit) | 72.6% |
| **A100 80GB** | 80GB | Qwen-32B (fp16) | 72.6% |
| **8Ã—A100** | 640GB | R1-671B (fp16) | 79.8% |

### í”„ë¡¬í”„íŒ… ê°€ì´ë“œ (ì¤‘ìš”!)

#### âŒ í”¼í•´ì•¼ í•  ê²ƒ

**Few-shot promptingì€ ì„±ëŠ¥ ì €í•˜!**

```python
# âŒ ë‚˜ìœ ì˜ˆì‹œ
bad_prompt = """
Here are some examples of how to solve math problems:

Example 1:
Q: What is 2+2?
A: <think>2+2=4</think> The answer is 4.

Example 2:
Q: What is 3Ã—5?
A: <think>3Ã—5=15</think> The answer is 15.

Now solve this:
Q: Solve x^2 + 5x + 6 = 0
"""

# ë¬¸ì œ:
# 1. Few-shot examplesê°€ ëª¨ë¸ì˜ ì¶”ë¡  íŒ¨í„´ ë°©í•´
# 2. ì˜ˆì œì˜ ê°„ë‹¨í•œ íŒ¨í„´ì„ ëª¨ë°©í•˜ë ¤ í•¨
# 3. ë³µì¡í•œ ë¬¸ì œì—ì„œ ì„±ëŠ¥ ì €í•˜ (~10% í•˜ë½)
```

#### âœ… ê¶Œì¥ ë°©ì‹

**Zero-shot with clear instructions**

```python
# âœ… ì¢‹ì€ ì˜ˆì‹œ
good_prompt = """
Solve the following problem step by step.
Show your reasoning process clearly.
Verify your answer before providing the final result.

Problem: Solve x^2 + 5x + 6 = 0

Provide your answer in this format:
<think>[Your detailed reasoning]</think>
Final Answer: [Your answer]
"""

# íš¨ê³¼:
# - ëª¨ë¸ì´ ììœ ë¡­ê²Œ ì¶”ë¡  ì „ëµ ì„ íƒ
# - ê¸´ Chain-of-Thought ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±
# - ìµœê³  ì„±ëŠ¥ ë°œíœ˜
```

#### í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ëª¨ìŒ

**1. ìˆ˜í•™ ë¬¸ì œ**

```python
math_template = """
Solve the following mathematical problem.

Requirements:
1. Show all steps clearly
2. Explain your reasoning
3. Verify your final answer
4. If multiple methods exist, compare them

Problem:
{problem_statement}

Format:
<think>
[Step-by-step solution with explanations]
</think>

Final Answer: [Answer in simplest form]
"""
```

**2. ì½”ë”© ë¬¸ì œ**

```python
coding_template = """
Implement a solution for the following programming challenge.

Requirements:
1. Analyze the problem and identify the optimal approach
2. Consider time and space complexity
3. Handle edge cases
4. Write clean, readable code
5. Provide test cases

Problem:
{problem_description}

Input format: {input_format}
Output format: {output_format}
Constraints: {constraints}

Provide:
<think>
[Problem analysis, approach, complexity analysis]
</think>

```code
[Your implementation]
```

Test cases:
[Example inputs and expected outputs]
"""
```

**3. ê³¼í•™ ì¶”ë¡ **

```python
science_template = """
Answer the following scientific question with detailed reasoning.

Requirements:
1. Recall relevant scientific principles
2. Apply principles step by step
3. Show calculations if needed
4. Verify the answer makes physical sense

Question:
{question}

Format:
<think>
[Relevant principles â†’ Application â†’ Calculation â†’ Verification]
</think>

Answer: [Concise final answer with units]
"""
```

### ë°°í¬ ì˜µì…˜

#### 1. API ì‚¬ìš© (ê°€ì¥ ê°„ë‹¨)

```python
# DeepSeek API
import openai

client = openai.OpenAI(
    api_key="your-deepseek-api-key",
    base_url="https://api.deepseek.com"
)

def solve_problem(problem):
    response = client.chat.completions.create(
        model="deepseek-reasoner",  # R1 ëª¨ë¸
        messages=[
            {
                "role": "user",
                "content": f"Solve step by step:\n{problem}"
            }
        ],
        temperature=0.6,  # ë…¼ë¬¸ ê¶Œì¥ê°’
        top_p=0.95,
        max_tokens=32768  # ê¸´ ì¶”ë¡  í—ˆìš©
    )

    return response.choices[0].message.content

# ì‚¬ìš© ì˜ˆì‹œ
problem = "Find the derivative of f(x) = x^3 * sin(x)"
solution = solve_problem(problem)
print(solution)
```

**ì¥ì :**
- ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
- ì¸í”„ë¼ ê´€ë¦¬ ë¶ˆí•„ìš”
- í•­ìƒ ìµœì‹  ë²„ì „

**ë‹¨ì :**
- ì‚¬ìš©ëŸ‰ì— ë”°ë¥¸ ë¹„ìš©
- ì¸í„°ë„· ì—°ê²° í•„ìš”
- ë°ì´í„° ì™¸ë¶€ ì „ì†¡

#### 2. ì˜¤í”ˆì†ŒìŠ¤ ë°°í¬ (ì¦ë¥˜ ëª¨ë¸)

**Option A: HuggingFace Transformers**

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# ëª¨ë¸ ì„ íƒ
model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"

# ëª¨ë¸ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,  # ë©”ëª¨ë¦¬ ì ˆì•½
    device_map="auto"  # ìë™ GPU ë°°ì¹˜
)

# ì¶”ë¡  í•¨ìˆ˜
def generate_solution(problem):
    prompt = f"Solve step by step:\n{problem}"

    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    outputs = model.generate(
        **inputs,
        max_new_tokens=32768,
        temperature=0.6,
        top_p=0.95,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id
    )

    solution = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return solution

# ì‚¬ìš©
problem = "Prove that sqrt(2) is irrational"
solution = generate_solution(problem)
print(solution)
```

**Option B: vLLM (í”„ë¡œë•ì…˜ ì„œë¹™)**

```bash
# ì„¤ì¹˜
pip install vllm

# ì„œë²„ ì‹œì‘
vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \
    --tensor-parallel-size 1 \
    --max-model-len 32768 \
    --dtype bfloat16 \
    --port 8000
```

```python
# í´ë¼ì´ì–¸íŠ¸ ì½”ë“œ
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"
)

response = client.completions.create(
    model="deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    prompt="Solve: âˆ« xÂ²e^x dx",
    max_tokens=32768,
    temperature=0.6
)

print(response.choices[0].text)
```

**ì¥ì :**
- ê³ ì„±ëŠ¥ (vLLM ìµœì í™”)
- ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
- OpenAI í˜¸í™˜ API

#### 3. ì–‘ìí™” ë°°í¬ (ë¦¬ì†ŒìŠ¤ ì œí•œ í™˜ê²½)

```python
# 4-bit ì–‘ìí™” (GPTQ)
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B-GPTQ"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    trust_remote_code=True
)

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ~4GB (ì›ë˜ ~14GB)
# ì„±ëŠ¥ ì €í•˜: ~2-3%
```

```python
# 8-bit ì–‘ìí™” (bitsandbytes)
from transformers import AutoModelForCausalLM, BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_threshold=6.0
)

model = AutoModelForCausalLM.from_pretrained(
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    quantization_config=quantization_config,
    device_map="auto"
)

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ~7GB
# ì„±ëŠ¥ ì €í•˜: ~1%
```

### ì‹¤ì „ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

#### ì‹œë‚˜ë¦¬ì˜¤ 1: ë°ì´í„° ë¶„ì„

**ë°°ê²½:** ê¸°ì—… ë‚´ë¶€ë§ì—ì„œ ë¯¼ê°í•œ ë°ì´í„° ë¶„ì„

```python
# ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬ (Qwen-14B)
import pandas as pd
from deepseek_client import DeepSeekModel

model = DeepSeekModel("Qwen-14B")

# CSV ë°ì´í„° ë¡œë“œ
sales_data = pd.read_csv("confidential_sales_2024.csv")

# ë¶„ì„ ìš”ì²­
prompt = f"""
Analyze the following sales data and provide insights:

Data summary:
{sales_data.describe().to_string()}

Top 5 products by revenue:
{sales_data.nlargest(5, 'revenue')[['product', 'revenue']].to_string()}

Tasks:
1. Identify key trends and patterns
2. Calculate month-over-month growth rates
3. Detect anomalies or outliers
4. Suggest actionable recommendations

Provide detailed reasoning and calculations.
"""

analysis = model.generate(prompt)
print(analysis)

# ê²°ê³¼:
# - ë³´ì•ˆ: ë°ì´í„° ì™¸ë¶€ ìœ ì¶œ ì—†ìŒ
# - ì„±ëŠ¥: o1-mini ìˆ˜ì¤€
# - ë¹„ìš©: API ë¹„ìš© ì œë¡œ
```

#### ì‹œë‚˜ë¦¬ì˜¤ 2: ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸

**ë°°ê²½:** ì•Œê³ ë¦¬ì¦˜ ëŒ€íšŒ ì¤€ë¹„

```python
# Codeforces ìŠ¤íƒ€ì¼ ë¬¸ì œ
problem = """
You are given an array of N integers.
Find the maximum sum of a non-empty subarray.

Constraints:
- 1 â‰¤ N â‰¤ 10^5
- -10^9 â‰¤ A[i] â‰¤ 10^9

Input:
5
-2 1 -3 4 -1

Expected Output:
4

Explanation: Subarray [4] has maximum sum 4.
"""

solution = model.generate(f"""
Solve this competitive programming problem:

{problem}

Requirements:
1. Analyze the problem and choose the optimal algorithm
2. Explain the approach and complexity
3. Implement a clean solution
4. Provide test cases

Think step by step.
""")

# DeepSeek-R1 ì¶œë ¥ (ìš”ì•½):
"""
<think>
This is the classic Maximum Subarray Sum problem (Kadane's Algorithm).

Approach:
- Dynamic programming
- State: max_ending_here = maximum sum ending at current position
- Recurrence: max_ending_here = max(arr[i], max_ending_here + arr[i])

Time Complexity: O(N)
Space Complexity: O(1)
</think>

```python
def max_subarray_sum(arr):
    max_so_far = float('-inf')
    max_ending_here = 0

    for num in arr:
        max_ending_here = max(num, max_ending_here + num)
        max_so_far = max(max_so_far, max_ending_here)

    return max_so_far

# Test
arr = [-2, 1, -3, 4, -1]
print(max_subarray_sum(arr))  # Output: 4
```
"""
```

#### ì‹œë‚˜ë¦¬ì˜¤ 3: êµìœ¡ìš© ìˆ˜í•™ ë¬¸ì œ í’€ì´

**ë°°ê²½:** ê³ ë“±í•™êµ ìˆ˜í•™ ì˜¨ë¼ì¸ ê³¼ì™¸

```python
# í•™ìƒ ì§ˆë¬¸
question = """
ì‚¼ê°í•¨ìˆ˜ ë¬¸ì œ:
sinÂ²x + cosÂ²x = 1 ì„ ì¦ëª…í•˜ì‹œì˜¤.
"""

# ë‹¨ê³„ë³„ ì„¤ëª… ìƒì„±
explanation = model.generate(f"""
ë‹¤ìŒ ìˆ˜í•™ ë¬¸ì œë¥¼ ê³ ë“±í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”:

{question}

ìš”êµ¬ì‚¬í•­:
1. ê° ë‹¨ê³„ë¥¼ ëª…í™•íˆ ì„¤ëª…
2. ìˆ˜ì‹ê³¼ í•¨ê»˜ ì§ê´€ì ì¸ ì„¤ëª… ì¶”ê°€
3. ê·¸ë¦¼ìœ¼ë¡œ í‘œí˜„ ê°€ëŠ¥í•œ ë¶€ë¶„ ì–¸ê¸‰
4. ë‹¤ë¥¸ ì¦ëª… ë°©ë²•ë„ ì†Œê°œ

ì¹œì ˆí•˜ê³  êµìœ¡ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
""", language="korean")

# ì¶œë ¥ (ìš”ì•½):
"""
<think>
ì´ ë¬¸ì œëŠ” í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ì™€ ì—°ê²°ëœ ì‚¼ê°í•¨ìˆ˜ì˜ ê¸°ë³¸ í•­ë“±ì‹ì…ë‹ˆë‹¤.

ì¦ëª… ë°©ë²• 1: ë‹¨ìœ„ì› ì´ìš© (ê°€ì¥ ì§ê´€ì )
ì¦ëª… ë°©ë²• 2: í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ ì§ì ‘ ì ìš©
</think>

ì¦ëª… ë°©ë²• 1: ë‹¨ìœ„ì›ìœ¼ë¡œ ì´í•´í•˜ê¸°

1ë‹¨ê³„: ë‹¨ìœ„ì› ê·¸ë¦¬ê¸°
- ë°˜ì§€ë¦„ì´ 1ì¸ ì›ì„ ê·¸ë¦½ë‹ˆë‹¤
- ì¤‘ì‹¬ì€ (0, 0), ë°˜ì§€ë¦„ = 1

2ë‹¨ê³„: ì  Pì˜ ì¢Œí‘œ
- ë‹¨ìœ„ì› ìœ„ì˜ ì  Pë¥¼ ê° xë§Œí¼ íšŒì „í•œ ìœ„ì¹˜ì— ì°ìœ¼ë©´
- Pì˜ ì¢Œí‘œëŠ” (cos x, sin x)

3ë‹¨ê³„: ê±°ë¦¬ ê³µì‹ ì ìš©
- ì›ì ì—ì„œ Pê¹Œì§€ ê±°ë¦¬ = 1 (ë°˜ì§€ë¦„)
- ê±°ë¦¬ ê³µì‹: âˆš[(cos x)Â² + (sin x)Â²] = 1
- ì–‘ë³€ì„ ì œê³±í•˜ë©´: cosÂ²x + sinÂ²x = 1

ì¦ëª… ì™„ë£Œ! âœ“

[ê·¸ë¦¼ìœ¼ë¡œ ë³´ë©´ ë” ì‰¬ì›Œìš”]
ì› ìœ„ì˜ ì ì€ í•­ìƒ ì›ì ìœ¼ë¡œë¶€í„° ê±°ë¦¬ 1ì´ë¯€ë¡œ,
ê°€ë¡œ(cos x)ì™€ ì„¸ë¡œ(sin x)ì˜ ì œê³±í•©ì€ í•­ìƒ 1ì…ë‹ˆë‹¤.

ë‹¤ë¥¸ ì¦ëª… ë°©ë²•:
ì§ê°ì‚¼ê°í˜•ì—ì„œ í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ë¥¼ ì§ì ‘ ì‚¬ìš©í•´ë„ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì–´ìš”!
"""
```

### ì„±ëŠ¥ ìµœì í™” íŒ

#### 1. ë°°ì¹˜ ì²˜ë¦¬

```python
# âŒ ëŠë¦° ë°©ë²•: í•˜ë‚˜ì”© ì²˜ë¦¬
for problem in problems:
    solution = model.generate(problem)
    solutions.append(solution)

# âœ… ë¹ ë¥¸ ë°©ë²•: ë°°ì¹˜ ì²˜ë¦¬
batch_size = 8
solutions = model.generate_batch(problems, batch_size=batch_size)

# ì†ë„ í–¥ìƒ: ì•½ 5-7ë°°
```

#### 2. KV Cache ì¬ì‚¬ìš©

```python
# ì—¬ëŸ¬ ë¬¸ì œë¥¼ ê°™ì€ ì»¨í…ìŠ¤íŠ¸ë¡œ í•´ê²°í•  ë•Œ
context = "You are a math tutor. Solve problems step by step."

# âŒ ë§¤ë²ˆ context ì¬ì²˜ë¦¬
for problem in problems:
    full_prompt = context + "\n\n" + problem
    solution = model.generate(full_prompt)

# âœ… KV cache ì¬ì‚¬ìš©
cache = model.create_cache(context)
for problem in problems:
    solution = model.generate(problem, cache=cache)
    # ì²« ë²ˆì§¸ ì´í›„ ~30% ë¹ ë¦„
```

#### 3. ì¶”ë¡  ê¸¸ì´ ì œí•œ

```python
# ê°„ë‹¨í•œ ë¬¸ì œëŠ” ì§§ê²Œ
simple_config = {
    "max_tokens": 4096,  # ê¸´ ì¶”ë¡  ë¶ˆí•„ìš”
    "temperature": 0.3   # ë” ê²°ì •ì 
}

# ë³µì¡í•œ ë¬¸ì œëŠ” ê¸¸ê²Œ
complex_config = {
    "max_tokens": 32768,  # ì¶©ë¶„í•œ ì¶”ë¡  ê³µê°„
    "temperature": 0.6    # ë‹¤ì–‘í•œ ì ‘ê·¼ í—ˆìš©
}

# ë¬¸ì œ ë‚œì´ë„ì— ë”°ë¼ config ì„ íƒ
if is_simple(problem):
    solution = model.generate(problem, **simple_config)
else:
    solution = model.generate(problem, **complex_config)
```

---

## ğŸŒ íŒ¨ëŸ¬ë‹¤ì„ ë³€í™”ì˜ ì˜ë¯¸

### AlphaGoì™€ì˜ ë¹„êµ

#### ì—­ì‚¬ì  ìœ ì‚¬ì„±

| íŠ¹ì„± | AlphaGo (2016) | DeepSeek-R1-Zero (2025) |
|------|---------------|------------------------|
| **ë„ë©”ì¸** | ë°”ë‘‘ (19Ã—19 ë³´ë“œ) | ìì—°ì–´ ì¶”ë¡  |
| **í•µì‹¬ í˜ì‹ ** | Self-playë§Œìœ¼ë¡œ ìµœê°• | Pure RLë§Œìœ¼ë¡œ ì¶”ë¡  ëŠ¥ë ¥ |
| **ë°ì´í„° ì˜ì¡´ë„** | í”„ë¡œ ê¸°ë³´ ë¶ˆí•„ìš” | Long CoT ë°ì´í„° ë¶ˆí•„ìš” |
| **ì°½ë°œ í˜„ìƒ** | "ì‹ ì˜ í•œ ìˆ˜" | "Aha moment" |
| **í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜** | ëŒ€êµ­ ë°˜ë³µ â†’ ì „ëµ ë°œê²¬ | CoT ìƒì„± â†’ ì¶”ë¡  íŒ¨í„´ ë°œê²¬ |
| **íŒŒê¸‰íš¨ê³¼** | AIê°€ ì¸ê°„ ì§€ëŠ¥ ì´ˆì›” ê°€ëŠ¥ | AIê°€ ìŠ¤ìŠ¤ë¡œ ì‚¬ê³  ë°©ë²• í•™ìŠµ |

#### ê³µí†µì : ìê¸°ì§„í™”(Self-Evolution)

```
AlphaGo:
â”œâ”€ ì´ˆê¸°: ë¬´ì‘ìœ„ ìˆ˜
â”œâ”€ ì¤‘ê¸°: ê¸°ë³¸ ì „ëµ ë°œê²¬ (ì„¸ë ¥, ì§‘ ë“±)
â””â”€ í›„ê¸°: ê³ ê¸‰ ì „ëµ ì°½ë°œ (ì‹ ì˜ í•œ ìˆ˜)

DeepSeek-R1-Zero:
â”œâ”€ ì´ˆê¸°: ì§§ì€ ì§ì ‘ ë‹µë³€
â”œâ”€ ì¤‘ê¸°: ìê¸°ê²€ì¦ ì¶”ê°€
â””â”€ í›„ê¸°: ë©”íƒ€ì¸ì§€ì  ì¶”ë¡  (aha moment, reflection)
```

**í•µì‹¬ í†µì°°:**
> "ì ì ˆí•œ ë³´ìƒ ì„¤ê³„ë§Œ ì£¼ì–´ì§€ë©´, AIëŠ” ìŠ¤ìŠ¤ë¡œ ê³ ê¸‰ ì „ëµì„ ë°œê²¬í•  ìˆ˜ ìˆë‹¤."

### AI ê°œë°œ ë°©ë²•ë¡ ì˜ ì „í™˜

#### Past: ë°ì´í„° ì¤‘ì‹¬ íŒ¨ëŸ¬ë‹¤ì„

```
More Data + Bigger Model = Better Performance

ë³‘ëª© í˜„ìƒ:
â”œâ”€ ê³ í’ˆì§ˆ ë°ì´í„° ìˆ˜ì§‘ ë¹„ìš©
â”‚   ì˜ˆ: GPT-4 í•™ìŠµì— ìˆ˜ë°±ë§Œ ë‹¬ëŸ¬
â”‚
â”œâ”€ ë¼ë²¨ë§ ë¹„ìš©
â”‚   ì˜ˆ: RLHFë¥¼ ìœ„í•œ ì¸ê°„ ì„ í˜¸ ë°ì´í„°
â”‚
â””â”€ ë°ì´í„° í”„ë¼ì´ë²„ì‹œ
    ì˜ˆ: ë¯¼ê°í•œ ë„ë©”ì¸ (ì˜ë£Œ, ë²•ë¥ )
```

#### Future: ìê¸°ì§„í™” ì¤‘ì‹¬ íŒ¨ëŸ¬ë‹¤ì„

```
Strong Base Model + Smart RL = Self-Discovered Capabilities

ì¥ì :
â”œâ”€ ë°ì´í„° ìš”êµ¬ëŸ‰ ê¸‰ê°
â”‚   DeepSeek-R1: ìˆ˜ì²œ ê°œ SFT vs ê¸°ì¡´ ìˆ˜ì‹­ë§Œ ê°œ
â”‚
â”œâ”€ ë„ë©”ì¸ ì ì‘ ìš©ì´
â”‚   ë³´ìƒ í•¨ìˆ˜ë§Œ ë°”ê¾¸ë©´ ìƒˆ ë„ë©”ì¸ í•™ìŠµ
â”‚
â””â”€ ì§€ì†ì  ê°œì„ 
    Self-playì²˜ëŸ¼ ê³„ì† ì§„í™” ê°€ëŠ¥
```

**ì‹¤ë¬´ì  í•¨ì˜:**

```python
# ê¸°ì¡´: ë°ì´í„° ìˆ˜ì§‘ì´ ë³‘ëª©
traditional_pipeline = {
    "step1": "ìˆ˜ì§‘ (months)",
    "step2": "ë¼ë²¨ë§ (months)",
    "step3": "SFT (weeks)",
    "step4": "RLHF (weeks)",
    "total": "6-12 months"
}

# ìƒˆë¡œìš´: RLì´ í•µì‹¬
new_pipeline = {
    "step1": "Base ëª¨ë¸ í™•ë³´ (ì¦‰ì‹œ)",
    "step2": "ë³´ìƒ ì„¤ê³„ (weeks)",
    "step3": "RL í›ˆë ¨ (weeks)",
    "step4": "ì¦ë¥˜ (weeks)",
    "total": "1-3 months"
}

# ê°œë°œ ì£¼ê¸°: 4-6ë°° ë‹¨ì¶•
```

### ì‚°ì—… êµ¬ì¡° ë³€í™”

#### 1. GPU ì˜ì¡´ë„ ì¬ê³ 

**"ë”¥ì‹œí¬ ì‡¼í¬" (2025ë…„ 1ì›” 27ì¼)**

```
ì´ë²¤íŠ¸:
â”œâ”€ DeepSeek-R1 ë°œí‘œ: "ê°œë°œ ë¹„ìš© 560ë§Œ ë‹¬ëŸ¬"
â”œâ”€ ì—”ë¹„ë””ì•„ ì£¼ê°€: -17% (ì‹œì´ 5890ì–µ ë‹¬ëŸ¬ ì¦ë°œ)
â”œâ”€ ë¹…í…Œí¬ ì£¼ê°€: ì¼ì œíˆ í•˜ë½
â””â”€ AI íˆ¬ìì: "ë” ì´ìƒ ë¹„ì‹¼ ì¹© í•„ìš” ì—†ë‚˜?"
```

**SemiAnalysis ë°˜ë°•:**

```
ì‹¤ì œ ë¹„ìš© ì¶”ì •:
â”œâ”€ ë°œí‘œëœ $5.6M: ì‚¬ì „í•™ìŠµë§Œ í¬í•¨
â”œâ”€ ë¯¸í¬í•¨ í•­ëª©:
â”‚   â”œâ”€ R&D ì¸ê±´ë¹„ (~$50M)
â”‚   â”œâ”€ ì¸í”„ë¼ êµ¬ì¶• (~$100M)
â”‚   â”œâ”€ ìš´ì˜ë¹„ (~$20M)
â”‚   â””â”€ ì‹¤íŒ¨í•œ ì‹¤í—˜ë“¤ (~$30M)
â”œâ”€ ì‹¤ì œ ì´ë¹„ìš© ì¶”ì •: ~$280M
â””â”€ ì—¬ì „íˆ GPT-4 ëŒ€ë¹„ ì €ë ´í•˜ì§€ë§Œ "í˜ëª…ì "ì€ ê³¼ì¥
```

**ì§„ì§œ ì˜ë¯¸:**

```yaml
GPU ì˜ì¡´ë„:
  ì˜¤í•´: "GPU ì—†ì´ë„ AI ê°œë°œ ê°€ëŠ¥"
  ì§„ì‹¤: "íš¨ìœ¨ì ì¸ ì•Œê³ ë¦¬ì¦˜ > ë¬´ì°¨ë³„ ìŠ¤ì¼€ì¼ë§"

  ë³€í™”:
    Before: "H100 10,000ì¥ í™•ë³´ê°€ ìµœìš°ì„ "
    After: "5,000ì¥ìœ¼ë¡œë„ ì¶©ë¶„í•  ìˆ˜ ìˆìŒ (ì•Œê³ ë¦¬ì¦˜ ê°œì„  ì‹œ)"

  ì˜í–¥:
    - GPU ê°€ê²© ì••ë°•
    - ì—”ë¹„ë””ì•„ ë…ì  ì™„í™” ê°€ëŠ¥ì„±
    - AMD, Intel ë“± ëŒ€ì•ˆ ì¹© ê¸°íšŒ
```

#### 2. ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ í™œì„±í™”

**ê°œë°œì ì»¤ë®¤ë‹ˆí‹°ì˜ ì¦‰ê° ë°˜ì‘:**

```python
# 1ì£¼ì¼ ë§Œì— ë‚˜ì˜¨ í˜ì‹ ë“¤

innovations = [
    {
        "í”„ë¡œì íŠ¸": "Unsloth",
        "ë‚´ìš©": "R1 ë©”ëª¨ë¦¬ ìµœì í™”",
        "ì„±ê³¼": "720GB â†’ 131GB (80% ê°ì†Œ)"
    },
    {
        "í”„ë¡œì íŠ¸": "llama.cpp",
        "ë‚´ìš©": "CPU ì¶”ë¡  ì§€ì›",
        "ì„±ê³¼": "GPU ì—†ì´ë„ ì‹¤í–‰ ê°€ëŠ¥"
    },
    {
        "í”„ë¡œì íŠ¸": "GGUF ì–‘ìí™”",
        "ë‚´ìš©": "4-bit ì••ì¶•",
        "ì„±ê³¼": "7B ëª¨ë¸ â†’ 4GB RAM"
    },
    {
        "í”„ë¡œì íŠ¸": "Fine-tuning ë ˆì‹œí”¼",
        "ë‚´ìš©": "ë„ë©”ì¸ ì ì‘ ê°€ì´ë“œ",
        "ì„±ê³¼": "ì˜ë£Œ, ë²•ë¥  ë“± íŠ¹í™” ë²„ì „"
    }
]
```

**ì˜¤í”ˆì†ŒìŠ¤ì˜ í˜:**

```
íì‡„í˜• (OpenAI o1):
â”œâ”€ ì ‘ê·¼: APIë§Œ ê°€ëŠ¥
â”œâ”€ ë¹„ìš©: ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ì¦ê°€
â”œâ”€ ì»¤ìŠ¤í„°ë§ˆì´ì§•: ë¶ˆê°€ëŠ¥
â””â”€ íˆ¬ëª…ì„±: ë‚®ìŒ

ì˜¤í”ˆì†ŒìŠ¤ (DeepSeek-R1):
â”œâ”€ ì ‘ê·¼: ì „ì²´ ê°€ì¤‘ì¹˜ ê³µê°œ
â”œâ”€ ë¹„ìš©: ì´ˆê¸° ì„¤ì • í›„ ë¬´ë£Œ
â”œâ”€ ì»¤ìŠ¤í„°ë§ˆì´ì§•: ì™„ì „ ê°€ëŠ¥
â””â”€ íˆ¬ëª…ì„±: ë†’ìŒ (ë…¼ë¬¸, ì½”ë“œ ëª¨ë‘ ê³µê°œ)

â†’ ì»¤ë®¤ë‹ˆí‹° í˜ì‹  ì†ë„: ì˜¤í”ˆì†ŒìŠ¤ >> íì‡„í˜•
```

#### 3. ê¸°ì—… AI ì „ëµ ë³€í™”

**Before DeepSeek-R1:**

```
ê¸°ì—… AI ë„ì… ì¥ë²½:
â”œâ”€ ì„±ëŠ¥: ì˜¨í”„ë ˆë¯¸ìŠ¤ ëª¨ë¸ ì„±ëŠ¥ ë¶€ì¡±
â”‚   êµ­ë‚´ ëª¨ë¸: AIME 5-10%
â”‚   vs í•„ìš” ìˆ˜ì¤€: 50%+
â”‚
â”œâ”€ ë³´ì•ˆ: ì™¸ë¶€ API ì‚¬ìš© ë¶ˆê°€
â”‚   ë¯¼ê°í•œ ë°ì´í„° â†’ ì™¸ë¶€ ì „ì†¡ ê¸ˆì§€
â”‚   ì˜ˆ: ì˜ë£Œ, ê¸ˆìœµ, êµ­ë°©
â”‚
â””â”€ ë¹„ìš©: ìƒìš© API ë¹„ìš© ë¶€ë‹´
    ëŒ€ëŸ‰ ì‚¬ìš© ì‹œ ì›” ìˆ˜ë°±ë§Œ ì›
```

**After DeepSeek-R1:**

```
ìƒˆë¡œìš´ ê°€ëŠ¥ì„±:
â”œâ”€ ì„±ëŠ¥: Qwen-7Bë¡œë„ ì¶©ë¶„
â”‚   AIME 55.5% (GPT-4o ëŒ€ë¹„ 6ë°°)
â”‚   ëŒ€ë¶€ë¶„ì˜ ì‹¤ë¬´ ì‘ì—… í•´ê²° ê°€ëŠ¥
â”‚
â”œâ”€ ë³´ì•ˆ: ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬ ê°€ëŠ¥
â”‚   ë‚´ë¶€ ì„œë²„ì— ì„¤ì¹˜ â†’ ë°ì´í„° ìœ ì¶œ ì—†ìŒ
â”‚   RTX 4090 1-2ì¥ì´ë©´ ì¶©ë¶„
â”‚
â””â”€ ë¹„ìš©: ì´ˆê¸° íˆ¬ì í›„ ë¬´ë£Œ
    í•˜ë“œì›¨ì–´ êµ¬ë§¤: $5K-20K (ì¼íšŒì„±)
    ìš´ì˜ë¹„: ì „ê¸°ë£Œë§Œ
```

**ê¸°ì—… ë„ì… ì‚¬ë¡€ (ê°€ìƒ ì˜ˆì‹œ):**

```yaml
Company: êµ­ë‚´ ëŒ€í˜• ë³‘ì›
Challenge: ì˜ë£Œ ê¸°ë¡ ë¶„ì„ ìë™í™”
  - ê¸°ì¡´ ì†”ë£¨ì…˜: í•´ì™¸ API (ë³´ì•ˆ ì´ìŠˆ)
  - í•„ìš” ì„±ëŠ¥: ê³ ë„ì˜ ì¶”ë¡  ëŠ¥ë ¥

Solution: DeepSeek-R1 ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬
  - ëª¨ë¸: Qwen-32B Distill
  - í•˜ë“œì›¨ì–´: A100 80GB Ã— 2ì¥
  - ì´ë¹„ìš©: ~$30K (í•˜ë“œì›¨ì–´)

Results:
  - ì„±ëŠ¥: o1-mini ìˆ˜ì¤€ (ì˜ë£Œ ë¬¸ì„œ ì´í•´ ìš°ìˆ˜)
  - ë³´ì•ˆ: ë°ì´í„° ë‚´ë¶€ë§ì—ë§Œ ì¡´ì¬
  - ë¹„ìš©: API ë¹„ìš© $0 (ê¸°ì¡´ ì›” $50K)
  - ROI: 2ê°œì›” ë§Œì— íšŒìˆ˜
```

### ë¯¸ì¤‘ AI ê²½ìŸì˜ ìƒˆë¡œìš´ êµ­ë©´

#### ë¯¸êµ­ì˜ GPU ìˆ˜ì¶œ ì œì¬ ìš°íšŒ

**íƒ€ì„ë¼ì¸:**

```
2023ë…„ 10ì›”:
â”œâ”€ ë¯¸êµ­: H100/A100 ëŒ€ì¤‘êµ­ ìˆ˜ì¶œ ê¸ˆì§€
â””â”€ ì¤‘êµ­: H800(ì„±ëŠ¥ ì œí•œ ë²„ì „)ë§Œ ì‚¬ìš© ê°€ëŠ¥

2024ë…„:
â”œâ”€ DeepSeek-V3 ë°œí‘œ (H800 ì‚¬ìš©)
â”‚   ì„±ëŠ¥: GPT-4 ìˆ˜ì¤€
â”‚   ë©”ì‹œì§€: "ì œí•œëœ ì¹©ìœ¼ë¡œë„ ê°€ëŠ¥"
â”‚
â””â”€ ë¯¸êµ­: ì¶”ê°€ ì œì¬ ê²€í† 

2025ë…„ 1ì›”:
â””â”€ DeepSeek-R1 ë°œí‘œ
    ì„±ëŠ¥: OpenAI o1 ìˆ˜ì¤€
    ì˜¤í”ˆì†ŒìŠ¤: MIT ë¼ì´ì„ ìŠ¤
    ì¶©ê²©: "ì¹© ë´‰ì‡„ ë¬´ë ¥í™”?"
```

**ê¸°ìˆ ì  ìš°íšŒ ë°©ë²•:**

```python
# ë¯¸êµ­ì˜ ì˜ë„: ì¤‘êµ­ì˜ AI ë°œì „ ì§€ì—°
us_strategy = {
    "ë°©ë²•": "ìµœê³ ê¸‰ GPU ê³µê¸‰ ì°¨ë‹¨",
    "ê¸°ëŒ€": "ì„±ëŠ¥ ì €í•˜ â†’ ê°œë°œ ì§€ì—°"
}

# ì¤‘êµ­ì˜ ëŒ€ì‘: íš¨ìœ¨ì„± ê·¹ëŒ€í™”
china_response = {
    "í•˜ë“œì›¨ì–´": "H800 (ì œí•œëœ ì„±ëŠ¥)",
    "ì†Œí”„íŠ¸ì›¨ì–´": "ì•Œê³ ë¦¬ì¦˜ ìµœì í™”",
    "ê²°ê³¼": "H100 ê¸‰ ì„±ëŠ¥ ë‹¬ì„±"
}

# ìµœì í™” ê¸°ë²•
optimizations = [
    "MoE (Mixture-of-Experts): í™œì„± íŒŒë¼ë¯¸í„° ì¤„ì´ê¸°",
    "Multi-head latent attention: ë©”ëª¨ë¦¬ íš¨ìœ¨",
    "Efficient RL: GRPOë¡œ Critic ì œê±°",
    "ì¦ë¥˜: í° ëª¨ë¸ â†’ ì‘ì€ ëª¨ë¸ ì§€ì‹ ì´ì „"
]
```

**í•¨ì˜:**

```
ê²°ë¡ :
â”œâ”€ ê¸°ìˆ  ê²©ì°¨: ê±°ì˜ ì‚¬ë¼ì§
â”‚   2023: 1-2ë…„ ë’¤ì²˜ì§
â”‚   2025: ë™ë“± ìˆ˜ì¤€
â”‚
â”œâ”€ ì œì¬ íš¨ê³¼: ì œí•œì 
â”‚   ì¹© ë´‰ì‡„ë§Œìœ¼ë¡œëŠ” ë¶ˆì¶©ë¶„
â”‚   ì•Œê³ ë¦¬ì¦˜ í˜ì‹ ì´ ìš°íšŒë¡œ
â”‚
â””â”€ ê²½ìŸ ì‹¬í™”: ê°€ì†í™”
    ì¤‘êµ­: ì œì•½ ì† í˜ì‹  ìê·¹
    ë¯¸êµ­: ê²½ê°ì‹¬ ê³ ì¡°
```

#### ê¸€ë¡œë²Œ AI ì§€í˜• ë³€í™”

```
2024ë…„ ì´ì „: ë¯¸êµ­ ë…ì£¼
â”œâ”€ OpenAI: GPT ì‹œë¦¬ì¦ˆ
â”œâ”€ Google: Gemini
â”œâ”€ Anthropic: Claude
â””â”€ Meta: Llama (ì˜¤í”ˆì†ŒìŠ¤)

2025ë…„ ì´í›„: ì–‘ê°• êµ¬ë„
â”œâ”€ ë¯¸êµ­: íì‡„í˜• ìµœì²¨ë‹¨ (o1, Gemini Ultra)
â””â”€ ì¤‘êµ­: ì˜¤í”ˆì†ŒìŠ¤ ìµœì²¨ë‹¨ (DeepSeek-R1)
    â†’ ë‚˜ë¨¸ì§€ êµ­ê°€ë“¤: ì¤‘êµ­ ì˜¤í”ˆì†ŒìŠ¤ í™œìš©

ì˜í–¥:
â”œâ”€ ê¸°ìˆ  ì£¼ë„ê¶Œ: ë¶„ì‚°
â”œâ”€ ê°œë°œ ë¹„ìš©: í•˜ë½
â”œâ”€ í˜ì‹  ì†ë„: ê°€ì†
â””â”€ ì ‘ê·¼ì„±: ëŒ€í­ í–¥ìƒ
```

---

## âš ï¸ í•œê³„ì  ë° ë¯¸ë˜ ë°©í–¥

### í˜„ì¬ì˜ í•œê³„ì  (ë…¼ë¬¸ Section 5)

#### 1. ì¼ë°˜ ëŠ¥ë ¥ ë¶€ì¡±

**Function Calling, JSON ì¶œë ¥:**

```python
# âŒ DeepSeek-R1: Function calling ì·¨ì•½
task = """
Call the weather API to get current temperature in Seoul.
Then format as JSON.
"""

# R1 ì¶œë ¥ (ë¬¸ì œ):
"""
<think>
To get weather, I need to call weather_api()
with location='Seoul'
</think>

I would call weather_api(location='Seoul') to get the temperature.
"""
# â†’ ì‹¤ì œ API í˜¸ì¶œ ì•ˆ í•¨, JSON í¬ë§· ì•„ë‹˜

# âœ… DeepSeek-V3: Function calling ëŠ¥ìˆ™
# â†’ ì‹¤ì œ API í˜¸ì¶œ + ì˜¬ë°”ë¥¸ JSON ì¶œë ¥
```

**ì›ì¸ ë¶„ì„:**
- R1ì€ ì¶”ë¡ ì—ë§Œ ìµœì í™”
- Function callingì€ ë¹„ì¶”ë¡  ì‘ì—…
- í›ˆë ¨ ë°ì´í„°ì— function calling ì˜ˆì œ ë¶€ì¡±

**í•´ê²° ë°©í–¥:**
```python
# Stage 3 ë°ì´í„° í™•ì¥
enhanced_data = {
    "reasoning": 60,000,  # ê¸°ì¡´
    "function_calling": 10,000,  # ì¶”ê°€
    "json_formatting": 5,000,  # ì¶”ê°€
    "general_qa": 20,000  # ê¸°ì¡´
}
```

#### 2. Multi-turn ëŒ€í™” ë¶€ì¡±

**ëŒ€í™” ë§¥ë½ ìœ ì§€ ë¬¸ì œ:**

```
User: 2ì°¨ ë°©ì •ì‹ xÂ²+5x+6=0ì„ í’€ì–´ì¤˜
R1: <think>...</think> x=-2 or x=-3

User: ê·¸ëŸ¼ ê·¼ê³¼ ê³„ìˆ˜ì˜ ê´€ê³„ëŠ”?
R1: <think>
Wait, what equation are we talking about?
Let me think about general quadratic equations...
</think>
For axÂ²+bx+c=0, sum of roots = -b/a

âŒ ì´ì „ ë°©ì •ì‹ (xÂ²+5x+6=0) ë§¥ë½ ìƒì‹¤
```

**ê·¼ë³¸ ì›ì¸:**
- ë‹¨ì¼ turn ì¶”ë¡ ì— ìµœì í™”
- ëŒ€í™” ì´ë ¥ í†µí•© ë©”ì»¤ë‹ˆì¦˜ ë¶€ì¡±

**ê°œì„  ë°©ì•ˆ:**
- Multi-turn ëŒ€í™” ë°ì´í„° ì¶”ê°€
- Conversation memory ë©”ì»¤ë‹ˆì¦˜ ì„¤ê³„

#### 3. ì–¸ì–´ ì§€ì› í¸í–¥

**ìµœì í™”ëœ ì–¸ì–´:**
- ì¤‘êµ­ì–´: â­â­â­â­â­
- ì˜ì–´: â­â­â­â­â­

**ì œí•œì  ì§€ì›:**
- í•œêµ­ì–´: â­â­â­ (ì–¸ì–´ í˜¼ìš© ë¬¸ì œ)
- ì¼ë³¸ì–´: â­â­â­
- ê¸°íƒ€ ì–¸ì–´: â­â­

**ì–¸ì–´ í˜¼ìš© ë¬¸ì œ ì˜ˆì‹œ:**

```
í•œêµ­ì–´ ì§ˆë¬¸: "íŒŒì´ì¬ìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ êµ¬í˜„"

R1 ì¶œë ¥ (ë¬¸ì œ):
"""
<think>
í”¼ë³´ë‚˜ì¹˜ sequence... let me think.
é€’å½’æ–¹æ³•... no wait, è¿­ä»£ä¼šæ›´å¥½
So I'll implement iterative approach
</think>

```python
def fibonacci(n):
    # í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ ìƒæˆ
    ...
```

ì½”ë“œëŠ” æ­£ç¡®çš„ã€‚
"""
```

**í•´ê²° ë°©í–¥:**
- ì–¸ì–´ë³„ ì¦ë¥˜ ëª¨ë¸ (ì˜ˆ: Qwen-7B-Korean)
- Language-specific reward ê°•í™”

#### 4. í”„ë¡¬í”„íŠ¸ ë¯¼ê°ë„

**Few-shot ì„±ëŠ¥ ì €í•˜:**

```python
# ì‹¤í—˜ ê²°ê³¼ (AIME 2024)
configs = {
    "zero-shot": 79.8,      # âœ… ê¶Œì¥
    "1-shot": 76.2,         # -3.6%p
    "3-shot": 72.1,         # -7.7%p
    "5-shot": 68.9          # -10.9%p
}

# ì›ì¸:
# - Few-shot examplesì˜ ì§§ì€ ì¶”ë¡  íŒ¨í„´ì— ì˜í–¥ë°›ìŒ
# - ëª¨ë¸ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ê¸´ CoTê°€ ì–µì œë¨
```

**í”„ë¡¬í”„íŠ¸ í˜•ì‹ ë¯¼ê°ë„:**

```python
# âœ… ì¢‹ì€ í”„ë¡¬í”„íŠ¸
good = "Solve step by step: [problem]"
â†’ ì„±ëŠ¥: 79.8%

# âŒ ë‚˜ìœ í”„ë¡¬í”„íŠ¸
bad = "Answer briefly: [problem]"
â†’ ì„±ëŠ¥: 45.3% (ì¶”ë¡  ì–µì œë¨)
```

#### 5. ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§

**SWE-bench ì„±ëŠ¥:**

```
ëª¨ë¸              SWE-bench Verified
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DeepSeek-R1       49.2%
DeepSeek-V3       48.7%  (ë¹„ìŠ·í•¨)
OpenAI o1         48.9%
Claude-3.7        40.6%
```

**ë¶„ì„:**
- ì¶”ë¡  ëª¨ë¸ì„ì—ë„ V3ì™€ ë¹„ìŠ·
- ì¶”ë¡  ëŠ¥ë ¥ì´ SWEì— ëœ ì¤‘ìš”?
- ì•„ë‹ˆë©´ ë‹¤ë¥¸ ë¬¸ì œ?

**SWE ì‘ì—…ì˜ íŠ¹ì„±:**

```python
# SWE-bench: ì‹¤ì œ GitHub issue í•´ê²°

challenges = {
    "ì½”ë“œë² ì´ìŠ¤ ì´í•´": "ìˆ˜ì²œ~ìˆ˜ë§Œ ì¤„ ì½”ë“œ íŒŒì•…",
    "ë””ë²„ê¹…": "ìˆ¨ê²¨ì§„ ë²„ê·¸ ì°¾ê¸°",
    "ì„¤ê³„ ê²°ì •": "ì•„í‚¤í…ì²˜ ìˆ˜ì¤€ íŒë‹¨",
    "í…ŒìŠ¤íŠ¸": "ì—£ì§€ ì¼€ì´ìŠ¤ ê³ ë ¤"
}

# í•„ìš”í•œ ëŠ¥ë ¥
requirements = {
    "ì¶”ë¡ ": "ì¤‘ìš”í•˜ì§€ë§Œ ì¼ë¶€",
    "ì½”ë“œ ì´í•´": "ë” ì¤‘ìš”",
    "ë„ë©”ì¸ ì§€ì‹": "ë§¤ìš° ì¤‘ìš”"
}
```

**ê°œì„  ë°©í–¥:**
- SWE íŠ¹í™” ë°ì´í„°ë¡œ RL
- ì½”ë“œë² ì´ìŠ¤ ë§¥ë½ ê´€ë¦¬ ê°•í™”

### ì‹¤íŒ¨í•œ ì‹œë„ë“¤ (Section 4.2)

ë…¼ë¬¸ì˜ íˆ¬ëª…í•œ ê³µìœ :

#### 1. Process Reward Model (PRM)

**ì‹œë„:**

```python
# ê° ì¶”ë¡  ë‹¨ê³„ë§ˆë‹¤ ì •í™•ì„± í‰ê°€
reasoning_steps = [
    "Step 1: Given equation xÂ² + 5x + 6 = 0",
    "Step 2: Factor: (x+2)(x+3) = 0",
    "Step 3: Therefore x = -2 or x = -3"
]

# PRMì´ ê° ë‹¨ê³„ í‰ê°€
prm_scores = [
    (step1, 1.0),  # ì •í™•
    (step2, 1.0),  # ì •í™•
    (step3, 1.0)   # ì •í™•
]
```

**ë¬¸ì œì :**

```
Issue 1: Fine-grain step ì •ì˜ ì–´ë ¤ì›€
â””â”€ "í•œ ë‹¨ê³„"ì˜ ê¸°ì¤€ì´ ëª¨í˜¸
   ì˜ˆ: "Factor: (x+2)(x+3)" í•œ ë‹¨ê³„? ë‘ ë‹¨ê³„?

Issue 2: ì¤‘ê°„ ë‹¨ê³„ ì •í™•ì„± íŒë‹¨ ì–´ë ¤ì›€
â””â”€ ë§ì•„ ë³´ì´ì§€ë§Œ í‹€ë¦° ê²½ìš°
   ì˜ˆ: "xÂ² + 5x + 6 = (x+1)(x+6)"
        â†’ ì „ê°œí•˜ë©´ xÂ² + 7x + 6 (í‹€ë¦¼)
        â†’ í•˜ì§€ë§Œ í˜•ì‹ì€ ë§ìŒ

Issue 3: Reward Hacking
â””â”€ ëª¨ë¸ì´ PRM ì†ì´ëŠ” ë²• í•™ìŠµ
   "ì´ë ‡ê²Œ ì“°ë©´ PRMì´ ë†’ì€ ì ìˆ˜ ì¤€ë‹¤"
   â†’ ì‹¤ì œ ì •í™•ë„ì™€ ë¬´ê´€
```

**ì‹¤í—˜ ê²°ê³¼:**
```python
results = {
    "without_PRM": {
        "AIME": 79.8,
        "training_stable": True
    },
    "with_PRM": {
        "AIME": 73.2,  # -6.6%p
        "training_stable": False,
        "reward_hacking": "ì‹¬ê°"
    }
}

# ê²°ë¡ : PRM ì‚¬ìš© ì•ˆ í•¨
```

#### 2. Monte Carlo Tree Search (MCTS)

**ì‹œë„:**

```python
# AlphaGo ìŠ¤íƒ€ì¼ tree search
def solve_with_mcts(problem):
    root = Node(problem)

    for iteration in range(1000):
        # Selection
        node = select_promising_node(root)

        # Expansion
        new_node = expand(node)

        # Simulation
        reward = simulate(new_node)

        # Backpropagation
        backpropagate(new_node, reward)

    return best_solution(root)
```

**ë¬¸ì œì :**

```
Issue 1: í­ë°œì  Search Space
â”œâ”€ ë°”ë‘‘: 19Ã—19 = 361 ê°€ëŠ¥í•œ ìˆ˜
â”œâ”€ ì¶”ë¡ : 50,000 í† í° ì–´íœ˜ Ã— ìˆ˜ì²œ ë‹¨ê³„
â””â”€ â†’ Combinatorial explosion

Issue 2: Value Model í•™ìŠµ ì–´ë ¤ì›€
â”œâ”€ "ì´ ì¤‘ê°„ ì¶”ë¡  ìƒíƒœê°€ ì¢‹ì€ê°€?" íŒë‹¨ ì–´ë ¤ì›€
â””â”€ ë°”ë‘‘ê³¼ ë‹¬ë¦¬ ëª…í™•í•œ í‰ê°€ ê¸°ì¤€ ì—†ìŒ

Issue 3: ê³„ì‚° ë¹„ìš©
â””â”€ InferenceëŠ” ë¹¨ë¼ì¡Œì§€ë§Œ
    Trainingì—ëŠ” ì ìš© ì‹¤íŒ¨
```

**ì‹¤í—˜ ê²°ê³¼:**

```python
results = {
    "inference_only": {
        "AIME": 82.1,  # +2.3%p (ì¢‹ìŒ!)
        "latency": "10x slower"
    },
    "iterative_training": {
        "convergence": False,
        "cost": "ë„ˆë¬´ ë†’ìŒ",
        "abandoned": True
    }
}

# ê²°ë¡ : Inferenceì—ë§Œ ì‚¬ìš© ê³ ë ¤
```

### ë¯¸ë˜ ì—°êµ¬ ë°©í–¥

#### ë‹¨ê¸° (6ê°œì›” ë‚´)

**1. ì¼ë°˜ ëŠ¥ë ¥ ê°•í™”**

```python
improvements = {
    "function_calling": {
        "ë°©ë²•": "10K+ function calling ë°ì´í„° ì¶”ê°€",
        "ëª©í‘œ": "GPT-4 ìˆ˜ì¤€ ë‹¬ì„±"
    },
    "json_output": {
        "ë°©ë²•": "Format constraint RL",
        "ëª©í‘œ": "êµ¬ì¡°í™”ëœ ì¶œë ¥ 100% ì •í™•"
    },
    "multi_turn": {
        "ë°©ë²•": "ëŒ€í™” ë§¥ë½ RL",
        "ëª©í‘œ": "10-turn ëŒ€í™” ë§¥ë½ ìœ ì§€"
    }
}
```

**2. ë‹¤êµ­ì–´ ì§€ì› í™•ëŒ€**

```python
multilingual_plan = {
    "í•œêµ­ì–´": "Qwen-Korean ì¦ë¥˜ ëª¨ë¸",
    "ì¼ë³¸ì–´": "Qwen-Japanese ì¦ë¥˜ ëª¨ë¸",
    "í”„ë‘ìŠ¤ì–´/ë…ì¼ì–´": "Qwen-European ì¦ë¥˜",

    "ë°©ë²•": {
        "step1": "ì–¸ì–´ë³„ ê³ í’ˆì§ˆ CoT ë°ì´í„° ìˆ˜ì§‘",
        "step2": "R1ì—ì„œ í•´ë‹¹ ì–¸ì–´ë¡œ ìƒì„±",
        "step3": "ì–¸ì–´ë³„ ì¦ë¥˜ ëª¨ë¸ í›ˆë ¨"
    }
}
```

**3. ì¶”ë¡  íš¨ìœ¨ ê°œì„ **

```python
efficiency = {
    "ë¬¸ì œ": "í‰ê·  8000 í† í° ì¶”ë¡  â†’ ëŠë¦¼, ë¹„ìŒˆ",

    "í•´ê²°ì±…": {
        "adaptive_length": {
            "ì•„ì´ë””ì–´": "ê°„ë‹¨í•œ ë¬¸ì œëŠ” ì§§ê²Œ",
            "ë°©ë²•": "ê¸¸ì´ ì¡°ì ˆ ë³´ìƒ",
            "ê¸°ëŒ€": "í‰ê·  ê¸¸ì´ 50% ê°ì†Œ"
        },
        "early_stopping": {
            "ì•„ì´ë””ì–´": "ë‹µ í™•ì‹ í•˜ë©´ ì¡°ê¸° ì¢…ë£Œ",
            "ë°©ë²•": "confidence threshold",
            "ê¸°ëŒ€": "ì§€ì—° 30% ê°ì†Œ"
        }
    }
}
```

#### ì¤‘ê¸° (1ë…„ ë‚´)

**1. Multimodal í™•ì¥**

```python
multimodal_reasoning = {
    "vision": {
        "ëª©í‘œ": "ì´ë¯¸ì§€ ê¸°ë°˜ ìˆ˜í•™ ë¬¸ì œ í•´ê²°",
        "ì˜ˆì‹œ": "ê¸°í•˜í•™ ê·¸ë¦¼ ë³´ê³  ì¦ëª…",
        "ë„ì „": "Visual reasoning íŒ¨í„´ í•™ìŠµ"
    },
    "code": {
        "ëª©í‘œ": "ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ ë°˜ì˜í•œ ë””ë²„ê¹…",
        "ì˜ˆì‹œ": "ëŸ°íƒ€ì„ ì˜¤ë¥˜ ë³´ê³  ì›ì¸ ì¶”ë¡ ",
        "ë„ì „": "Code execution feedback loop"
    }
}
```

**2. ë” íš¨ìœ¨ì ì¸ RL ì•Œê³ ë¦¬ì¦˜**

```python
advanced_rl = {
    "current": "GRPO",

    "improvements": {
        "hierarchical_rl": {
            "ì•„ì´ë””ì–´": "ê³ ìˆ˜ì¤€/ì €ìˆ˜ì¤€ ì¶”ë¡  ë¶„ë¦¬",
            "ê¸°ëŒ€": "ìƒ˜í”Œ íš¨ìœ¨ 2x í–¥ìƒ"
        },
        "curriculum_learning": {
            "ì•„ì´ë””ì–´": "ì‰¬ìš´ ë¬¸ì œ â†’ ì–´ë ¤ìš´ ë¬¸ì œ",
            "ê¸°ëŒ€": "ìˆ˜ë ´ ì†ë„ 3x í–¥ìƒ"
        },
        "meta_learning": {
            "ì•„ì´ë””ì–´": "í•™ìŠµ ë°©ë²• ìì²´ë¥¼ í•™ìŠµ",
            "ê¸°ëŒ€": "ìƒˆ ë„ë©”ì¸ ì ì‘ 10x ë¹ ë¦„"
        }
    }
}
```

**3. ë„ë©”ì¸ íŠ¹í™” ë²„ì „**

```python
specialized_versions = {
    "R1-Medical": {
        "ë°ì´í„°": "ì˜í•™ ë…¼ë¬¸, ì„ìƒ ì¼€ì´ìŠ¤",
        "ëª©í‘œ": "ì˜ì‚¬ êµ­ê°€ê³ ì‹œ 90%+",
        "í™œìš©": "ì§„ë‹¨ ë³´ì¡°, ì¹˜ë£Œ ê³„íš"
    },
    "R1-Legal": {
        "ë°ì´í„°": "íŒë¡€, ë²•ë¥  ë¬¸ì„œ",
        "ëª©í‘œ": "ë³€í˜¸ì‚¬ ì‹œí—˜ 80%+",
        "í™œìš©": "ë²•ë¥  ìë¬¸, ê³„ì•½ ë¶„ì„"
    },
    "R1-Science": {
        "ë°ì´í„°": "ê³¼í•™ ë…¼ë¬¸, ì‹¤í—˜ ë°ì´í„°",
        "ëª©í‘œ": "PhD ìˆ˜ì¤€ ì—°êµ¬ ì§€ì›",
        "í™œìš©": "ê°€ì„¤ ìƒì„±, ì‹¤í—˜ ì„¤ê³„"
    }
}
```

#### ì¥ê¸° (2-3ë…„)

**1. ë²”ìš© AGIë¥¼ ìœ„í•œ ì¶”ë¡  í”„ë ˆì„ì›Œí¬**

```python
agi_reasoning = {
    "ëª©í‘œ": "ëª¨ë“  ì§€ì  ì‘ì—…ì— ì ìš© ê°€ëŠ¥í•œ ì¶”ë¡ ",

    "components": {
        "abstract_reasoning": "ê°œë… ìˆ˜ì¤€ ì‚¬ê³ ",
        "analogical_reasoning": "ìœ ì¶”ë¥¼ í†µí•œ ë¬¸ì œ í•´ê²°",
        "creative_reasoning": "ìƒˆë¡œìš´ í•´ê²°ì±… ë°œëª…",
        "social_reasoning": "ì¸ê°„ ìƒí˜¸ì‘ìš© ì´í•´"
    },

    "challenge": "ì´ë“¤ì„ í†µí•©í•˜ëŠ” ë©”íƒ€ ì¶”ë¡  ì‹œìŠ¤í…œ"
}
```

**2. ìê¸°ì§„í™” ë©”ì»¤ë‹ˆì¦˜ì˜ ì´ë¡ ì  ì´í•´**

```python
theoretical_understanding = {
    "ì§ˆë¬¸": [
        "ì™œ RLë§Œìœ¼ë¡œ ë³µì¡í•œ ì¶”ë¡ ì´ ì°½ë°œí•˜ëŠ”ê°€?",
        "ì–´ë–¤ ì¡°ê±´ì—ì„œ 'aha moment'ê°€ ë‚˜íƒ€ë‚˜ëŠ”ê°€?",
        "ìê¸°ê²€ì¦ ëŠ¥ë ¥ì˜ ìˆ˜í•™ì  ëª¨ë¸ì€?"
    ],

    "ì ‘ê·¼": {
        "ìˆ˜í•™ì  ë¶„ì„": "ìµœì í™” ì´ë¡ , ì •ë³´ ì´ë¡ ",
        "ì‹¤í—˜ì  ì—°êµ¬": "Controlled ablation studies",
        "ì‹ ê²½ê³¼í•™ ì—°ê³„": "ì¸ê°„ ì¶”ë¡ ê³¼ ë¹„êµ"
    },

    "ê¸°ëŒ€ íš¨ê³¼": "ë” íš¨ìœ¨ì ì¸ RL ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„"
}
```

**3. ì¸ê°„-AI í˜‘ì—… ì¶”ë¡ **

```python
collaborative_reasoning = {
    "vision": "AIê°€ ì¸ê°„ì˜ ì¶”ë¡ ì„ ë³´ì¡°í•˜ê³  í™•ì¥",

    "scenarios": {
        "scientific_discovery": {
            "ì¸ê°„": "ì§ê´€, ì°½ì˜ì  ê°€ì„¤",
            "AI": "ëŒ€ê·œëª¨ ë°ì´í„° ë¶„ì„, ì—„ë°€í•œ ì¦ëª…",
            "ê²°ê³¼": "ìƒˆë¡œìš´ ê³¼í•™ì  ë°œê²¬ ê°€ì†í™”"
        },
        "strategic_planning": {
            "ì¸ê°„": "ê°€ì¹˜ íŒë‹¨, ìœ¤ë¦¬ì  ê³ ë ¤",
            "AI": "ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„, ìµœì í™”",
            "ê²°ê³¼": "ë” ë‚˜ì€ ì˜ì‚¬ê²°ì •"
        }
    }
}
```

---

## ğŸ’¼ ì‹¤ë¬´ìë¥¼ ìœ„í•œ ê°€ì´ë“œ

### ë„ì… ê²€í†  ì²´í¬ë¦¬ìŠ¤íŠ¸

```python
# ì²´í¬ë¦¬ìŠ¤íŠ¸: DeepSeek-R1 ë„ì… íƒ€ë‹¹ì„± í‰ê°€

checklist = {
    "1. ìš”êµ¬ì‚¬í•­ ë¶„ì„": {
        "ì¶”ë¡  ë³µì¡ë„": {
            "ì§ˆë¬¸": "ì‘ì—…ì´ ë³µì¡í•œ ì¶”ë¡ ì„ ìš”êµ¬í•˜ëŠ”ê°€?",
            "ì˜ˆì‹œ": {
                "High": "ìˆ˜í•™ ì¦ëª…, ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„, ê³¼í•™ ë¶„ì„",
                "Medium": "ë°ì´í„° í•´ì„, ì½”ë“œ ë¦¬ë·°",
                "Low": "ê°„ë‹¨í•œ QA, ë²ˆì—­, ìš”ì•½"
            },
            "íŒë‹¨": "High/Mediumì´ë©´ R1 ê³ ë ¤, Lowë©´ ì¼ë°˜ LLM"
        },

        "ì‘ë‹µ ì‹œê°„ ìš”êµ¬ì‚¬í•­": {
            "ì§ˆë¬¸": "ê¸´ ì¶”ë¡  ì‹œê°„(5-30ì´ˆ)ì„ í—ˆìš©í•  ìˆ˜ ìˆëŠ”ê°€?",
            "íŒë‹¨": {
                "ì‹¤ì‹œê°„ ì±—ë´‡": "âŒ R1 ë¶€ì í•©",
                "ë°°ì¹˜ ë¶„ì„": "âœ… R1 ì í•©",
                "ë³´ì¡° ë„êµ¬": "âœ… R1 ì í•©"
            }
        },

        "ì •í™•ë„ vs ì†ë„": {
            "trade_off": {
                "ìµœê³  ì •í™•ë„ í•„ìš”": "R1-671B (ëŠë¦¼)",
                "ë°¸ëŸ°ìŠ¤": "Qwen-32B Distill",
                "ë¹ ë¥¸ ì‘ë‹µ": "Qwen-7B Distill"
            }
        }
    },

    "2. ì¸í”„ë¼ í‰ê°€": {
        "GPU ê°€ìš©ì„±": {
            "ì—†ìŒ": "API ì‚¬ìš© or í´ë¼ìš°ë“œ",
            "RTX 3090/4090": "Qwen-7B",
            "A100 40GB": "Qwen-32B",
            "8Ã—A100": "R1-671B"
        },

        "ë„¤íŠ¸ì›Œí¬ í™˜ê²½": {
            "ì¸í„°ë„· ê°€ëŠ¥": "API or í´ë¼ìš°ë“œ ë°°í¬",
            "ë‚´ë¶€ë§ë§Œ": "ì˜¨í”„ë ˆë¯¸ìŠ¤ í•„ìˆ˜ â†’ ì¦ë¥˜ ëª¨ë¸"
        },

        "ë³´ì•ˆ ìš”êµ¬ì‚¬í•­": {
            "ë°ì´í„° ì™¸ë¶€ ì „ì†¡ ê°€ëŠ¥": "API ì‚¬ìš© OK",
            "ë¯¼ê°í•œ ë°ì´í„°": "ì˜¨í”„ë ˆë¯¸ìŠ¤ í•„ìˆ˜"
        }
    },

    "3. ë¹„ìš© ë¶„ì„": {
        "API ì‚¬ìš©": {
            "ì´ˆê¸° ë¹„ìš©": "$0",
            "ì›” ì‚¬ìš©ë£Œ": "ì˜ˆìƒ ì¿¼ë¦¬ ìˆ˜ Ã— ê°€ê²©",
            "ì¥ì ": "ì¦‰ì‹œ ì‹œì‘, ìœ ì§€ë³´ìˆ˜ ì—†ìŒ",
            "ë‹¨ì ": "ì§€ì†ì  ë¹„ìš©, ë°ì´í„° ì „ì†¡"
        },

        "ì˜¨í”„ë ˆë¯¸ìŠ¤": {
            "ì´ˆê¸° ë¹„ìš©": "$5K-100K (í•˜ë“œì›¨ì–´)",
            "ì›” ì‚¬ìš©ë£Œ": "ì „ê¸°ë£Œ (~$100-500)",
            "ì¥ì ": "ì¥ê¸°ì ìœ¼ë¡œ ì €ë ´, ë°ì´í„° ë³´ì•ˆ",
            "ë‹¨ì ": "ì´ˆê¸° íˆ¬ì, ìš´ì˜ ë¶€ë‹´"
        },

        "Break-even ë¶„ì„": {
            "ì›” API ë¹„ìš©": "$X",
            "ì˜¨í”„ë ˆë¯¸ìŠ¤ ì´ˆê¸° ë¹„ìš©": "$Y",
            "íšŒìˆ˜ ê¸°ê°„": "Y / X ê°œì›”"
        }
    },

    "4. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸": {
        "POC ë‹¨ê³„": {
            "step1": "ëŒ€í‘œ ë¬¸ì œ 10-20ê°œ ì„ ì •",
            "step2": "APIë¡œ í…ŒìŠ¤íŠ¸ (Qwen-7B)",
            "step3": "ì •í™•ë„ í‰ê°€",
            "step4": "Go/No-go ê²°ì •"
        },

        "ë²¤ì¹˜ë§ˆí‚¹": {
            "ìì‚¬ ë°ì´í„°": "ì‹¤ì œ ì—…ë¬´ ë°ì´í„°ë¡œ í‰ê°€ í•„ìˆ˜",
            "ê³µê°œ ë²¤ì¹˜ë§ˆí¬": "ì°¸ê³ ìš©",
            "ë¹„êµ ëŒ€ìƒ": "ê¸°ì¡´ ì†”ë£¨ì…˜ vs R1"
        },

        "í”„ë¡¬í”„íŠ¸ ìµœì í™”": {
            "ì¤‘ìš”": "Few-shot í”¼í•˜ê³  Zero-shot ì‚¬ìš©",
            "ì‹¤í—˜": "ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ í˜•ì‹ í…ŒìŠ¤íŠ¸",
            "ë¬¸ì„œí™”": "ìµœì  í”„ë¡¬í”„íŠ¸ íŒ¨í„´ ê¸°ë¡"
        }
    },

    "5. ë°°í¬ ì „ëµ": {
        "Phase 1: POC (2-4ì£¼)": {
            "ëª©í‘œ": "ê¸°ìˆ  ê²€ì¦",
            "ë°©ë²•": "API ì‚¬ìš©",
            "ë²”ìœ„": "ì œí•œëœ use case",
            "í‰ê°€": "ì •í™•ë„, ì‚¬ìš©ì„±"
        },

        "Phase 2: Pilot (1-2ê°œì›”)": {
            "ëª©í‘œ": "ì‹¤ë¬´ ì ìš© ê²€ì¦",
            "ë°©ë²•": "ì¦ë¥˜ ëª¨ë¸ ì˜¨í”„ë ˆë¯¸ìŠ¤ or í´ë¼ìš°ë“œ",
            "ë²”ìœ„": "1-2ê°œ ë¶€ì„œ",
            "í‰ê°€": "ì„±ëŠ¥, ë¹„ìš©, ì‚¬ìš©ì ë§Œì¡±ë„"
        },

        "Phase 3: í”„ë¡œë•ì…˜ (3-6ê°œì›”)": {
            "ëª©í‘œ": "ì „ì‚¬ í™•ëŒ€",
            "ë°©ë²•": "ì•ˆì •ì  ì¸í”„ë¼ êµ¬ì¶•",
            "ë²”ìœ„": "ëª¨ë“  í•´ë‹¹ ë¶€ì„œ",
            "í‰ê°€": "ROI, ì¥ê¸° ìœ ì§€ë³´ìˆ˜"
        }
    }
}
```

### ë°ì´í„° ë¶„ì„ê°€ ê°€ì´ë“œ

#### í™œìš© ì‹œë‚˜ë¦¬ì˜¤ë³„ ê¶Œì¥ ì‚¬í•­

**ì‹œë‚˜ë¦¬ì˜¤ 1: CSV ë°ì´í„° íƒìƒ‰ì  ë¶„ì„**

```python
# ì¶”ì²œ ëª¨ë¸: Qwen-7B (ë¹ ë¥´ê³  ì¶©ë¶„í•œ ì„±ëŠ¥)

import pandas as pd

df = pd.read_csv("sales_data.csv")

prompt = f"""
Analyze the following sales dataset:

Dataset Info:
- Rows: {len(df)}
- Columns: {list(df.columns)}

Sample Data (first 5 rows):
{df.head().to_string()}

Statistical Summary:
{df.describe().to_string()}

Tasks:
1. Identify key trends in sales over time
2. Detect any anomalies or outliers
3. Calculate important metrics (growth rate, seasonality)
4. Provide actionable insights

Show your reasoning process step by step.
"""

analysis = model.generate(prompt)

# ê¸°ëŒ€ ì¶œë ¥:
"""
<think>
Looking at the data:

1. Trend Analysis:
   - Sales show upward trend from Q1 to Q4
   - Month-over-month growth: avg 5.2%
   - Q4 has seasonal spike (+23% vs Q3)

2. Outliers:
   - December sales: $1.2M (3 std dev above mean)
   - Possible cause: Holiday season
   - Recommendation: Prepare inventory for next Dec

3. Key Metrics:
   - YoY growth: 18.7%
   - Customer retention: 67%
   - Average order value: $245

4. Actionable Insights:
   - Focus marketing on Q4 preparation
   - Investigate customer churn (33%)
   - Consider upselling (AOV below industry avg $280)
</think>

[Detailed analysis with specific numbers and recommendations]
"""
```

**ì‹œë‚˜ë¦¬ì˜¤ 2: ë³µì¡í•œ í†µê³„ ë¶„ì„**

```python
# ì¶”ì²œ ëª¨ë¸: Qwen-32B (ê³ ê¸‰ í†µê³„ ì¶”ë¡  í•„ìš”)

prompt = """
Perform a multivariate regression analysis:

Dataset: Housing prices
Variables:
- Dependent: Price ($)
- Independent: Size (sqft), Age (years), Location (categorical),
               School Rating (1-10)

Tasks:
1. Check assumptions (linearity, normality, multicollinearity)
2. Build regression model
3. Interpret coefficients with confidence intervals
4. Assess model fit (RÂ², adjusted RÂ², residual analysis)
5. Identify influential observations
6. Make predictions with uncertainty quantification

Provide step-by-step statistical reasoning.
"""

# ê¸°ëŒ€: í†µê³„ì ìœ¼ë¡œ ì—„ë°€í•œ ë¶„ì„ + í•´ì„
```

**ì‹œë‚˜ë¦¬ì˜¤ 3: ë¹ ë¥¸ ë°ì´í„° íƒìƒ‰**

```python
# ì¶”ì²œ ëª¨ë¸: Qwen-1.5B (ì´ˆê³ ì† ì‘ë‹µ)

quick_prompt = """
Quick summary of this dataset:
{data_sample}

What are the top 3 insights?
"""

# 3-5ì´ˆ ë‚´ ë‹µë³€
# ìƒì„¸í•œ ë¶„ì„ì€ í•„ìš” ì—†ê³  ë¹ ë¥¸ overview ì›í•  ë•Œ
```

### í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¼ì´ë¸ŒëŸ¬ë¦¬

#### ìˆ˜í•™ ë¬¸ì œ

```python
math_prompt_template = """
Solve the following mathematical problem.

Problem Type: {problem_type}
Difficulty: {difficulty}

Problem Statement:
{problem}

Requirements:
1. Show all intermediate steps clearly
2. Explain the reasoning behind each step
3. If multiple solution methods exist, compare them
4. Verify your final answer
5. Express answer in simplest form

Format:
<think>
[Detailed step-by-step solution]
- Step 1: ...
- Step 2: ...
- Verification: ...
</think>

Final Answer: [Answer with units if applicable]
"""

# ì‚¬ìš© ì˜ˆì‹œ
problem = {
    "problem_type": "Calculus",
    "difficulty": "Advanced",
    "problem": "Find âˆ« xÂ² Â· e^x dx"
}

prompt = math_prompt_template.format(**problem)
```

#### ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„

```python
algorithm_prompt_template = """
Design an algorithm for the following problem.

Problem:
{problem_description}

Input Format:
{input_format}

Output Format:
{output_format}

Constraints:
{constraints}

Requirements:
1. Analyze the problem and identify optimal approach
2. Explain time and space complexity
3. Consider edge cases
4. Provide clean, well-commented implementation
5. Include test cases with expected outputs

Think through the problem systematically.

Format:
<think>
[Problem analysis]
- Understanding: ...
- Approach options: ...
- Chosen approach: ... (with justification)
- Complexity analysis: ...
- Edge cases: ...
</think>

```language
[Implementation]
```

Test Cases:
[Input â†’ Expected Output]
"""

# ì‚¬ìš© ì˜ˆì‹œ
problem = {
    "problem_description": "Find longest palindromic substring",
    "input_format": "string s (1 â‰¤ |s| â‰¤ 1000)",
    "output_format": "longest palindromic substring",
    "constraints": "Time limit: 2 seconds"
}
```

#### ê³¼í•™ ì§ˆë¬¸

```python
science_prompt_template = """
Answer the following scientific question with rigorous reasoning.

Domain: {domain}
Question:
{question}

Requirements:
1. State relevant scientific principles
2. Apply principles step by step
3. Show all calculations
4. Verify answer makes physical sense
5. Discuss assumptions and limitations

Format:
<think>
[Scientific reasoning]
- Relevant principles: ...
- Given information: ...
- Approach: ...
- Calculations: ...
- Verification: ...
- Assumptions: ...
</think>

Answer: [Concise answer with appropriate units and significant figures]
"""

# ì‚¬ìš© ì˜ˆì‹œ
question = {
    "domain": "Physics (Thermodynamics)",
    "question": """
    Calculate the final temperature when 100g of water at 80Â°C
    is mixed with 200g of water at 20Â°C.
    Assume no heat loss to surroundings.
    """
}
```

### ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# í”„ë¡œë•ì…˜ ë°°í¬ ì‹œ ëª¨ë‹ˆí„°ë§ í•„ìˆ˜

class DeepSeekR1Monitor:
    def __init__(self):
        self.metrics = {
            "accuracy": [],
            "latency": [],
            "token_usage": [],
            "errors": []
        }

    def log_inference(self, question, answer, ground_truth, latency):
        # ì •í™•ë„
        is_correct = self.verify(answer, ground_truth)
        self.metrics["accuracy"].append(is_correct)

        # ì§€ì—°ì‹œê°„
        self.metrics["latency"].append(latency)

        # í† í° ì‚¬ìš©ëŸ‰
        tokens = self.count_tokens(answer)
        self.metrics["token_usage"].append(tokens)

        # ì—ëŸ¬ ê°ì§€
        if self.has_error(answer):
            self.metrics["errors"].append({
                "question": question,
                "answer": answer,
                "timestamp": datetime.now()
            })

    def get_report(self):
        return {
            "accuracy": np.mean(self.metrics["accuracy"]),
            "avg_latency": np.mean(self.metrics["latency"]),
            "p95_latency": np.percentile(self.metrics["latency"], 95),
            "avg_tokens": np.mean(self.metrics["token_usage"]),
            "error_rate": len(self.metrics["errors"]) / len(self.metrics["accuracy"])
        }

    def alert_if_degraded(self):
        recent_accuracy = np.mean(self.metrics["accuracy"][-100:])

        if recent_accuracy < 0.7:  # Threshold
            send_alert(f"Accuracy dropped to {recent_accuracy}")
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸ ë° ë¬¸ì„œ

1. **ì›ë³¸ ë…¼ë¬¸**:
   - DeepSeek-AI. (2025). "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
   - arXiv: 2501.12948
   - PDF: https://arxiv.org/pdf/2501.12948

2. **ê´€ë ¨ ê¸°ìˆ  ë¸”ë¡œê·¸**:
   - DeepSeek ê³µì‹ ë¸”ë¡œê·¸: https://www.deepseek.com/
   - HuggingFace Model Card: https://huggingface.co/deepseek-ai

3. **ë¯¸ë””ì–´ ë¶„ì„**:
   - MIT Technology Review: "The DeepSeek Shock"
   - SemiAnalysis: Cost analysis debunking
   - HEARTCOUNT: Practical data analysis guide

### êµ¬í˜„ ë¦¬ì†ŒìŠ¤

```yaml
Official Implementations:
  - Model Weights: https://huggingface.co/deepseek-ai
  - API Documentation: https://api-docs.deepseek.com

Community Resources:
  - Unsloth Optimization: https://github.com/unslothai/unsloth
  - vLLM Serving: https://github.com/vllm-project/vllm
  - llama.cpp: https://github.com/ggerganov/llama.cpp

Tutorials:
  - Fine-tuning Guide: https://github.com/deepseek-ai/DeepSeek-R1
  - Deployment Best Practices: Community wikis
```

### ì¶”ê°€ ì½ì„ê±°ë¦¬

**ê°•í™”í•™ìŠµ ê¸°ì´ˆ:**
- Sutton & Barto: "Reinforcement Learning: An Introduction"
- PPO ë…¼ë¬¸: Schulman et al. (2017)
- GRPO ìƒì„¸: DeepSeek technical report

**ì¶”ë¡  ëŠ¥ë ¥ ì—°êµ¬:**
- Chain-of-Thought: Wei et al. (2022)
- Self-Consistency: Wang et al. (2022)
- Tree of Thoughts: Yao et al. (2023)

**ì¦ë¥˜ ê¸°ë²•:**
- Knowledge Distillation: Hinton et al. (2015)
- DistilBERT: Sanh et al. (2019)
- Task-Specific Distillation: Recent advances

---

## ğŸ¯ ê²°ë¡ 

### DeepSeek-R1ì˜ í˜ëª…ì  ê¸°ì—¬

#### 1. ê¸°ìˆ ì  ëŒíŒŒêµ¬

**í•µì‹¬ ë°œê²¬:**
> "Supervised Fine-Tuning ì—†ì´ë„ ìˆœìˆ˜ ê°•í™”í•™ìŠµë§Œìœ¼ë¡œ
> OpenAI o1 ìˆ˜ì¤€ì˜ ì¶”ë¡  ëŠ¥ë ¥ ë‹¬ì„± ê°€ëŠ¥"

**ì˜ë¯¸:**
```
ê¸°ì¡´ ë¯¿ìŒ: "ê³ í’ˆì§ˆ CoT ë°ì´í„°ê°€ ì¶”ë¡  ëŠ¥ë ¥ì˜ í•µì‹¬"
ìƒˆë¡œìš´ ì§„ì‹¤: "ì ì ˆí•œ ë³´ìƒ ì„¤ê³„ë¡œ ì¶”ë¡  íŒ¨í„´ ìë™ ë°œí˜„"

ì˜í–¥:
â”œâ”€ ë°ì´í„° ìˆ˜ì§‘ ë¹„ìš© ê¸‰ê°
â”œâ”€ ê°œë°œ ì£¼ê¸° ë‹¨ì¶• (6-12ê°œì›” â†’ 1-3ê°œì›”)
â””â”€ ìƒˆë¡œìš´ ë„ë©”ì¸ ì ì‘ ìš©ì´
```

#### 2. ê²½ì œì  íŒŒê¸‰íš¨ê³¼

**AI ì‚°ì—… êµ¬ì¡° ì¬í¸:**
```
Before: "ë” ë§ì€ GPU = ë” ì¢‹ì€ AI"
After: "ìŠ¤ë§ˆíŠ¸í•œ ì•Œê³ ë¦¬ì¦˜ > ë¬´ì°¨ë³„ ìŠ¤ì¼€ì¼ë§"

ì‹¤ì œ ì˜í–¥:
â”œâ”€ ì—”ë¹„ë””ì•„ ì£¼ê°€ -17% (2025.1.27)
â”œâ”€ AI ê°œë°œ ë¹„ìš© êµ¬ì¡° ì¬ê³ 
â””â”€ ì˜¤í”ˆì†ŒìŠ¤ vs íì‡„í˜• ê²½ìŸ ê²©í™”
```

#### 3. AI ë¯¼ì£¼í™”

**ì˜¤í”ˆì†ŒìŠ¤ í˜ëª…:**
```yaml
ì ‘ê·¼ì„±:
  - MIT ë¼ì´ì„ ìŠ¤ (ìƒì—…ì  ì´ìš© ììœ )
  - ëª¨ë¸ ê°€ì¤‘ì¹˜ ì „ë©´ ê³µê°œ
  - ë‹¤ì–‘í•œ í¬ê¸° (1.5B ~ 671B)

ì‹¤ìš©ì„±:
  - 7B ëª¨ë¸: ì¼ë°˜ PCì—ì„œ ì‹¤í–‰
  - ì„±ëŠ¥: GPT-4o ëŒ€ë¹„ 6ë°° (AIME)
  - ë¹„ìš©: ì´ˆê¸° íˆ¬ì í›„ ë¬´ë£Œ

íŒŒê¸‰:
  - ê¸°ì—…: ì˜¨í”„ë ˆë¯¸ìŠ¤ AI ê°€ëŠ¥
  - ì—°êµ¬ì: ìµœì²¨ë‹¨ ë„êµ¬ ì ‘ê·¼
  - ê°œë°œì: ìƒˆ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°€ì†í™”
```

### ì‹¤ë¬´ìë¥¼ ìœ„í•œ í•µì‹¬ ë©”ì‹œì§€

#### ì–¸ì œ DeepSeek-R1ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ê°€?

**âœ… ì í•©í•œ ê²½ìš°:**
1. ë³µì¡í•œ ì¶”ë¡ ì´ í•„ìš”í•œ ì‘ì—… (ìˆ˜í•™, ì½”ë”©, ê³¼í•™)
2. ì •í™•ë„ê°€ ìµœìš°ì„  (ì‘ë‹µ ì‹œê°„ 5-30ì´ˆ í—ˆìš©)
3. ë°ì´í„° ë³´ì•ˆ ì¤‘ìš” (ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬)
4. ì¥ê¸°ì  ë¹„ìš© ì ˆê° ëª©í‘œ

**âŒ ë¶€ì í•©í•œ ê²½ìš°:**
1. ì‹¤ì‹œê°„ ì‘ë‹µ í•„ìš” (<1ì´ˆ)
2. ë‹¨ìˆœ ì‘ì—… (QA, ë²ˆì—­, ìš”ì•½)
3. Function calling, JSON ì¶œë ¥ ì¤‘ìš”
4. Multi-turn ëŒ€í™” ì¤‘ì‹¬

