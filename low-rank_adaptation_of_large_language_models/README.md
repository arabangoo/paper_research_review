# LoRA: Low-Rank Adaptation of Large Language Models - λ…Όλ¬Έ λ¦¬λ·°

> **λ€κ·λ¨ μ–Έμ–΄ λ¨λΈμ ν¨μ¨μ  νμΈνλ‹: ν•™μµ κ°€λ¥ν• νλΌλ―Έν„° μλ¥Ό 10,000λ°° μ¤„μ΄λ©΄μ„ μ„±λ¥μ€ λ™λ“±ν•κ²**

[![arXiv](https://img.shields.io/badge/arXiv-2106.09685-b31b1b.svg)](https://arxiv.org/abs/2106.09685)
[![Publication Date](https://img.shields.io/badge/Published-June%202021-blue)]()
[![ICLR](https://img.shields.io/badge/ICLR-2022-green)]()

**μ €μ**: Edward J. Hu, Yelong Shen, Phillip Wallis μ™Έ (Microsoft)   
**λ°ν‘**: ICLR 2022   
**arXiv**: https://arxiv.org/abs/2106.09685   

---

## π“‹ λ©μ°¨

- [λ…Όλ¬Έ μ†κ° λ° ν•µμ‹¬ κ°€μΉ](#λ…Όλ¬Έ-μ†κ°-λ°-ν•µμ‹¬-κ°€μΉ)
- [μ—°κµ¬ λ°°κ²½ λ° λ™κΈ°](#μ—°κµ¬-λ°°κ²½-λ°-λ™κΈ°)
- [ν•µμ‹¬ μ•„μ΄λ””μ–΄: Low-Rank κ°€μ„¤](#ν•µμ‹¬-μ•„μ΄λ””μ–΄-low-rank-κ°€μ„¤)
- [LoRA λ°©λ²•λ΅ ](#lora-λ°©λ²•λ΅ )
- [μ‹¤ν— κ²°κ³Ό](#μ‹¤ν—-κ²°κ³Ό)
- [Ablation Study](#ablation-study)
- [μ‹¤μ‚¬μ© μμ‹](#μ‹¤μ‚¬μ©-μμ‹)
- [ν•κ³„μ  λ° λ―Έλ λ°©ν–¥](#ν•κ³„μ -λ°-λ―Έλ-λ°©ν–¥)
- [μ°Έκ³  μλ£](#μ°Έκ³ -μλ£)

---

## π― λ…Όλ¬Έ μ†κ° λ° ν•µμ‹¬ κ°€μΉ

### Executive Summary

LoRA(Low-Rank Adaptation)λ” Microsoftμ—μ„ λ°ν‘ν• **νλΌλ―Έν„° ν¨μ¨μ  νμΈνλ‹(PEFT)** κΈ°λ²•μΌλ΅, μ‚¬μ „ ν•™μµλ λ¨λΈμ κ°€μ¤‘μΉλ¥Ό λ™κ²°ν• μ±„ κ° Transformer λ μ΄μ–΄μ— ν•™μµ κ°€λ¥ν• **μ €μ°¨μ›(low-rank) ν–‰λ ¬**μ„ μ‚½μ…ν•λ” λ°©μ‹μ…λ‹λ‹¤.

### π† ν•µμ‹¬ μ„±κ³Ό

| μ§€ν‘ | LoRA | Full Fine-tuning |
|------|------|-----------------|
| **ν•™μµ κ°€λ¥ν• νλΌλ―Έν„°** | GPT-3 λ€λΉ„ 0.01% | 100% (175B) |
| **GPU λ©”λ¨λ¦¬** | ~3λ°° κ°μ† | κΈ°μ¤€ |
| **μ¶”λ΅  μ§€μ—° μ‹κ°„** | **0 (μ¦κ°€ μ—†μ)** | κΈ°μ¤€ |
| **μ„±λ¥** | λ™λ“± λλ” μ°μ„ | κΈ°μ¤€ |
| **μ €μ¥ ν¬κΈ°** | μ²΄ν¬ν¬μΈνΈ 10,000λ°° κ°μ† | κΈ°μ¤€ |

### π’΅ μ™ μ΄ λ…Όλ¬Έμ΄ μ¤‘μ”ν•κ°€?

**Before LoRA:**
```
GPT-3(175B) νμΈνλ‹
β”β”€ ν•„μ” GPU: A100 80GB Γ— μμ‹­ μ¥
β”β”€ μ €μ¥ κ³µκ°„: 175B Γ— float32 = 700GB
β”β”€ μ¶”λ΅ : λ¨λΈ κµμ²΄ ν•„μ” (νƒμ¤ν¬λ‹Ή λ³„λ„ λ°°ν¬)
β””β”€ λΉ„μ©: ν„μ‹¤μ μΌλ΅ λ¶κ°€λ¥ν• μμ¤€
```

**After LoRA:**
```
GPT-3(175B) + LoRA
β”β”€ ν•™μµ νλΌλ―Έν„°: ~4.7M (0.003%)
β”β”€ μ €μ¥ κ³µκ°„: ~35MB (νƒμ¤ν¬λ‹Ή)
β”β”€ μ¶”λ΅ : μ›λ³Έ κ°€μ¤‘μΉ + LoRA λ³‘ν•© β†’ μ¶”κ°€ μ§€μ—° μ—†μ
β””β”€ λΉ„μ©: λ€ν­ κ°μ†, μ‹¤μ©μ  μμ¤€
```

---

## π”™ μ—°κµ¬ λ°°κ²½ λ° λ™κΈ°

### κΈ°μ΅΄ Full Fine-Tuningμ λ¬Έμ 

GPT-3(175B), Megatron-LM, T5 κ°™μ€ μ΄λ€ν• μ–Έμ–΄ λ¨λΈμ΄ λ“±μ¥ν•λ©΄μ„, μ΄λ¥Ό λ‹¤μ΄μ¤νΈλ¦Ό νƒμ¤ν¬μ— μ μ©ν•κΈ° μ„ν• νμΈνλ‹μ λΉ„μ©μ΄ κΈ‰κ²©ν μ¦κ°€ν–μµλ‹λ‹¤.

**1. λ©”λ¨λ¦¬ λ¬Έμ **
```
Full Fine-tuning λ©”λ¨λ¦¬ κµ¬μ„±:
β”β”€ νλΌλ―Έν„°: 175B Γ— 4byte = 700GB
β”β”€ Gradient: 700GB
β”β”€ Optimizer State (Adam): 700GB Γ— 2 = 1400GB
β””β”€ μ΄ν•©: ~2800GB (A100 80GB 35μ¥ ν•„μ”)
```

**2. λ°°ν¬ λ¬Έμ **
- νƒμ¤ν¬λ§λ‹¤ λ³„λ„μ 175B λ¨λΈμ„ μ €μ¥ν•΄μ•Ό ν•¨
- μ„λΉ„μ¤ κµμ²΄ μ‹ μ—„μ²­λ‚ I/O λ° λ©”λ¨λ¦¬ λΉ„μ©

**3. κΈ°μ΅΄ λ€μ•λ“¤μ ν•κ³„**

| λ°©λ²• | μ•„μ΄λ””μ–΄ | ν•κ³„ |
|------|---------|------|
| **Adapter** | λ μ΄μ–΄ μ‚¬μ΄μ— μ‘μ€ MLP μ‚½μ… | μμ°¨ μ²λ¦¬ β†’ μ¶”λ΅  μ§€μ—° μ¦κ°€ |
| **Prefix Tuning** | μ…λ ¥μ— ν•™μµ κ°€λ¥ν• ν† ν° μ¶”κ°€ | μ‹ν€€μ¤ κΈΈμ΄ κ°μ†, ν•™μµ λ¶μ•μ • |
| **Prompt Tuning** | μ†ν”„νΈ ν”„λ΅¬ν”„νΈ ν•™μµ | λ€ν• λ¨λΈμ—μ„λ§ ν¨κ³Όμ  |
| **BitFit** | Biasλ§ μ—…λ°μ΄νΈ | μ„±λ¥ ν•κ³„ |

---

## π’΅ ν•µμ‹¬ μ•„μ΄λ””μ–΄: Low-Rank κ°€μ„¤

### Intrinsic Dimensionality μ—°κµ¬μ—μ„ μ¶λ°

Aghajanyan et al. (2020)μ μ—°κµ¬λ” μ‚¬μ „ ν•™μµλ μ–Έμ–΄ λ¨λΈμ΄ μ‹¤μ λ΅λ” **λ§¤μ° λ‚®μ€ λ‚΄μ¬μ  μ°¨μ›(intrinsic dimension)**μ—μ„ λ™μ‘ν•¨μ„ λ³΄μ€μµλ‹λ‹¤.

> **ν•µμ‹¬ μ£Όμ¥**: "μ‚¬μ „ ν•™μµλ λ¨λΈμ κ°€μ¤‘μΉ λ³€ν™”λ‰(Ξ”W)μ€ μ‹¤μ λ΅ λ‚®μ€ λ­ν¬(rank)λ¥Ό κ°€μ§„λ‹¤."

### μ§κ΄€μ  μ΄ν•΄

```
μ‚¬μ „ ν•™μµλ κ±°λ€ λ¨λΈ W β β„^(dΓ—k):
β”β”€ μ΄λ―Έ μ—„μ²­λ‚ μ–‘μ μ§€μ‹μ„ μΈμ½”λ”©
β”β”€ μƒλ΅μ΄ νƒμ¤ν¬ μ μ‘μ— ν•„μ”ν• λ³€ν™”(Ξ”W)λ” μƒλ€μ μΌλ΅ λ‹¨μ
β””β”€ Ξ”Wκ°€ μ €μ°¨μ› κµ¬μ΅°λ¥Ό κ°€μ§ κ²ƒμ΄λΌλ” κ°€μ„¤

μμ‹: d=4096, k=4096μΈ ν–‰λ ¬ Ξ”W (μ•½ 16M νλΌλ―Έν„°)
β†’ rank=4μ§λ¦¬ λ¶„ν•΄: B(4096Γ—4) Γ— A(4Γ—4096) = λ‹¨ 32K νλΌλ―Έν„°
```

### Low-Rank λ¶„ν•΄μ ν‘ν„λ ¥

```
Full rank ν–‰λ ¬ Ξ”W:
[w11 w12 ... w1k]
[w21 w22 ... w2k]
...
[wd1 wd2 ... wdk]
(dΓ—k = 16M νλΌλ―Έν„°)

Low-rank λ¶„ν•΄ Ξ”W = BA (rank r=4):
B = [b11 b12 b13 b14]    A = [a11 a12 ... a1k]
    [b21 b22 b23 b24]        [a21 a22 ... a2k]
    ...                      [a31 a32 ... a3k]
    [bd1 bd2 bd3 bd4]        [a41 a42 ... a4k]
(dΓ—r + rΓ—k = 32K νλΌλ―Έν„°, 500λ°° μ••μ¶•!)
```

---

## π—οΈ LoRA λ°©λ²•λ΅ 

### 1. μμ‹ λ° κµ¬μ΅°

**κΈ°μ΅΄ Forward Pass:**
```
h = Wβ‚€x
```

**LoRA μ μ© ν›„:**
```
h = Wβ‚€x + Ξ”Wx = Wβ‚€x + BAx
```

μ—¬κΈ°μ„:
- `Wβ‚€ β β„^(dΓ—k)`: λ™κ²°λ μ‚¬μ „ ν•™μµ κ°€μ¤‘μΉ
- `B β β„^(dΓ—r)`: ν•™μµ κ°€λ¥ν• ν–‰λ ¬ (0μΌλ΅ μ΄κΈ°ν™”)
- `A β β„^(rΓ—k)`: ν•™μµ κ°€λ¥ν• ν–‰λ ¬ (κ°€μ°μ‹μ•μΌλ΅ μ΄κΈ°ν™”)
- `r << min(d, k)`: λ­ν¬ ν•μ΄νΌνλΌλ―Έν„°

**μ¤μΌ€μΌλ§ ν©ν„°:**
```
h = Wβ‚€x + (Ξ±/r) Β· BAx
```
- `Ξ±`: μ¤μΌ€μΌλ§ μƒμ (λ³΄ν†µ rκ³Ό λ™μΌν•κ±°λ‚ 2λ°°)
- ν•™μµλ¥  μ΅°μ • μ—†μ΄ λ­ν¬ rμ„ λ³€κ²½ν•λ”λΌλ„ μ—…λ°μ΄νΈ κ·λ¨κ°€ μΌκ΄€λκ² μ μ§€

### 2. μ΄κΈ°ν™” μ „λµ

```python
# LoRA ν–‰λ ¬ μ΄κΈ°ν™”
# A: κ°€μ°μ‹μ• (λλ¤ μ΄κΈ°ν™”)
A = torch.randn(r, k) * 0.01

# B: 0μΌλ΅ μ΄κΈ°ν™”
B = torch.zeros(d, r)

# ν•™μµ μ‹μ‘ μ‹ Ξ”W = BA = 0
# β†’ μ²μμ—λ” μ›λ³Έ λ¨λΈκ³Ό λ™μΌν•κ² λ™μ‘
# β†’ ν•™μµμ΄ μ§„ν–‰λλ©΄μ„ Ξ”Wκ°€ ν•μ„±λ¨
```

**μ™ μ΄λ ‡κ² μ΄κΈ°ν™”ν•λ”κ°€?**
- `B=0`μΌλ΅ μ‹μ‘ β†’ `Ξ”W=0` β†’ ν•™μµ μ΄κΈ°μ— μ›λ³Έ λ¨λΈ κ·Έλ€λ΅ λ³΄μ΅΄
- μ•μ •μ μΈ νμΈνλ‹ μ‹μ‘μ  ν™•λ³΄

### 3. μ μ© μ„μΉ

λ…Όλ¬Έμ—μ„λ” Transformerμ **Attention κ°€μ¤‘μΉ ν–‰λ ¬**μ— μ μ©ν•©λ‹λ‹¤.

```
Transformer Self-Attention:
β”β”€ W_q (Query ν–‰λ ¬)  β† LoRA μ μ©
β”β”€ W_k (Key ν–‰λ ¬)    β† μ‹¤ν—μ—μ„λ” μ„ νƒμ 
β”β”€ W_v (Value ν–‰λ ¬)  β† LoRA μ μ©
β””β”€ W_o (μ¶λ ¥ ν–‰λ ¬)   β† μ‹¤ν—μ—μ„λ” μ„ νƒμ 

Feed-Forward Network:
β”β”€ W_1              β† μ„ νƒμ  (λ³΄ν†µ μƒλµ)
β””β”€ W_2              β† μ„ νƒμ  (λ³΄ν†µ μƒλµ)
```

**λ…Όλ¬Έμ ν•µμ‹¬ λ°κ²¬:** λ™μΌν• νλΌλ―Έν„° μμ‚° λ‚΄μ—μ„λ” W_qμ™€ W_vμ—λ§ LoRAλ¥Ό μ μ©ν•λ λ­ν¬λ¥Ό λ†’μ΄λ” κ²ƒλ³΄λ‹¤, λ” λ§μ€ λ μ΄μ–΄μ— λ‚®μ€ λ­ν¬λ΅ μ μ©ν•λ” κ²ƒμ΄ λ” ν¨κ³Όμ 

### 4. μ¶”λ΅  μ‹ κ°€μ¤‘μΉ λ³‘ν•©

LoRAμ κ°€μ¥ ν° μ¥μ : **μ¶”λ΅  μ§€μ—° μ—†μ**

```python
# ν•™μµ ν›„ κ°€μ¤‘μΉ λ³‘ν•©
W_merged = Wβ‚€ + B @ A  # (Ξ±/r μ¤μΌ€μΌλ§ ν¬ν•¨)

# μ΄ν›„ μ¶”λ΅ μ€ μΌλ° λ¨λΈκ³Ό λ™μΌ
output = W_merged @ x
```

```
Adapter λ°©μ‹ μ¶”λ΅ :
x β†’ Wβ‚€ β†’ Adapter(x) β†’ μ¶λ ¥  (μμ°¨ μ²λ¦¬, μ§€μ—° μμ)

LoRA μ¶”λ΅  (λ³‘ν•© ν›„):
x β†’ Wβ‚€ + Ξ”W β†’ μ¶λ ¥  (λ‹¨μΌ ν–‰λ ¬ κ³±, μ§€μ—° μ—†μ)
```

### 5. PyTorch κµ¬ν„

```python
import torch
import torch.nn as nn
import math

class LoRALinear(nn.Module):
    """LoRAλ¥Ό μ μ©ν• Linear λ μ΄μ–΄"""

    def __init__(
        self,
        in_features: int,
        out_features: int,
        rank: int = 4,
        alpha: float = 1.0,
        dropout: float = 0.0
    ):
        super().__init__()
        self.rank = rank
        self.alpha = alpha
        self.scaling = alpha / rank

        # μ›λ³Έ κ°€μ¤‘μΉ (λ™κ²°)
        self.weight = nn.Parameter(
            torch.empty(out_features, in_features),
            requires_grad=False  # λ™κ²°
        )

        # LoRA ν–‰λ ¬ (ν•™μµ κ°€λ¥)
        self.lora_A = nn.Parameter(
            torch.empty(rank, in_features)  # A: κ°€μ°μ‹μ• μ΄κΈ°ν™”
        )
        self.lora_B = nn.Parameter(
            torch.zeros(out_features, rank)  # B: 0μΌλ΅ μ΄κΈ°ν™”
        )

        self.dropout = nn.Dropout(p=dropout)

        # μ΄κΈ°ν™”
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))
        # lora_Bλ” μ΄λ―Έ 0μΌλ΅ μ΄κΈ°ν™”

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # μ›λ³Έ κ²½λ΅
        base_output = nn.functional.linear(x, self.weight)

        # LoRA κ²½λ΅
        lora_output = (
            self.dropout(x) @ self.lora_A.T @ self.lora_B.T
        ) * self.scaling

        return base_output + lora_output

    def merge_weights(self) -> None:
        """μ¶”λ΅ μ„ μ„ν•΄ LoRA κ°€μ¤‘μΉλ¥Ό μ›λ³Έμ— λ³‘ν•©"""
        self.weight.data += (self.lora_B @ self.lora_A) * self.scaling


class LoRAAttention(nn.Module):
    """Multi-Head Attentionμ— LoRA μ μ©"""

    def __init__(self, embed_dim, num_heads, rank=4, alpha=1.0):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads

        # Query, Key, Value, Output ν–‰λ ¬μ— LoRA μ μ©
        self.q_proj = LoRALinear(embed_dim, embed_dim, rank=rank, alpha=alpha)
        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=False)  # LoRA λ―Έμ μ©
        self.v_proj = LoRALinear(embed_dim, embed_dim, rank=rank, alpha=alpha)
        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=False)

    def forward(self, x, mask=None):
        B, T, C = x.shape

        Q = self.q_proj(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)
        K = self.k_proj(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)
        V = self.v_proj(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)

        scale = self.head_dim ** -0.5
        attn = (Q @ K.transpose(-2, -1)) * scale
        if mask is not None:
            attn = attn.masked_fill(mask == 0, float('-inf'))
        attn = attn.softmax(dim=-1)

        out = (attn @ V).transpose(1, 2).contiguous().view(B, T, C)
        return self.out_proj(out)
```

---

## π“ μ‹¤ν— κ²°κ³Ό

### 1. RoBERTa & DeBERTa (GLUE λ²¤μΉλ§ν¬)

**RoBERTa-base κ²°κ³Ό:**

| λ°©λ²• | ν•™μµ νλΌλ―Έν„° | MNLI | SST-2 | MRPC | CoLA | QNLI | ν‰κ·  |
|------|-------------|------|-------|------|------|------|------|
| Full FT | 125M | 87.6 | 94.8 | 90.2 | 63.6 | 92.8 | 85.8 |
| BitFit | 0.1M | 84.7 | 93.7 | 90.8 | 62.0 | 91.8 | 84.6 |
| Adapter | 0.3M | 87.1 | 94.5 | 88.4 | 60.8 | 93.0 | 84.8 |
| Prefix | 0.1M | 84.0 | 94.5 | 88.4 | 57.4 | 92.9 | 83.4 |
| **LoRA** | **0.3M** | **87.5** | **95.1** | **90.5** | **63.4** | **93.3** | **85.9** |

**DeBERTa-XXL κ²°κ³Ό:**

| λ°©λ²• | ν•™μµ νλΌλ―Έν„° | MNLI | SST-2 | MRPC | CoLA | QNLI | ν‰κ·  |
|------|-------------|------|-------|------|------|------|------|
| Full FT | 1.5B | 91.7 | 97.2 | 92.0 | 72.0 | 96.0 | 89.8 |
| **LoRA** | **4.7M** | **91.9** | **96.9** | **92.6** | **72.4** | **96.3** | **90.0** |

Full Fine-tuning λ€λΉ„ 0.3% νλΌλ―Έν„°λ§ μ‚¬μ©ν•λ©΄μ„ **λ™λ“± μ΄μƒμ μ„±λ¥** λ‹¬μ„±!

### 2. GPT-2 (μμ—°μ–΄ μƒμ„±)

**E2E NLG λ²¤μΉλ§ν¬:**

| λ°©λ²• | ν•™μµ νλΌλ―Έν„° | BLEU | NIST | MET | ROUGE-L | CIDEr |
|------|-------------|------|------|-----|---------|-------|
| GPT-2 Medium FT | 345M | 68.2 | 8.62 | 46.2 | 71.0 | 2.47 |
| GPT-2 Large FT | 774M | 68.5 | 8.78 | 46.0 | 69.9 | 2.45 |
| Adapter (M) | 0.37M | 66.3 | 8.41 | 45.0 | 69.8 | 2.40 |
| Prefix (M) | 0.35M | 69.7 | 8.81 | 46.1 | 71.4 | 2.49 |
| **LoRA (M)** | **0.35M** | **70.4** | **8.85** | **46.8** | **71.8** | **2.53** |

LoRAκ°€ **λ” ν° Full Fine-tuning λ¨λΈλ³΄λ‹¤λ„ μ°μ**ν• μ„±λ¥!

### 3. GPT-3 175B (ν•µμ‹¬ μ‹¤ν—)

GPT-3μ κ²½μ° Full Fine-tuning μμ²΄κ°€ μ‚¬μ‹¤μƒ λ¶κ°€λ¥ν• μ¤μΌ€μΌ.

**WikiSQL (ν…μ¤νΈβ†’SQL):**

| λ°©λ²• | ν•™μµ νλΌλ―Έν„° | μ •ν™•λ„ |
|------|-------------|--------|
| GPT-3 Zero-shot | 0 | 70.1% |
| GPT-3 Few-shot (prompt) | 0 | 78.4% |
| Full Fine-tuning (μ°Έκ³ ) | 175B | 79.2% |
| **LoRA (r=4)** | **4.7M** | **73.4%** |
| **LoRA (r=4, λ” λ§μ€ λ μ΄μ–΄)** | **37.7M** | **79.9%** |

**MultiNLI:**

| λ°©λ²• | ν•™μµ νλΌλ―Έν„° | μ •ν™•λ„ |
|------|-------------|--------|
| GPT-3 Zero-shot | 0 | 40.6% |
| Full Fine-tuning | 175B | 89.5% |
| **LoRA** | **4.7M** | **91.7%** |

Full Fine-tuningλ³΄λ‹¤ **λ” λ†’μ€ μ„±λ¥** λ‹¬μ„± (0.003% νλΌλ―Έν„°λ΅)!

### 4. ν•™μµ ν¨μ¨ λΉ„κµ

```
GPT-3 175B νμΈνλ‹ λΉ„κµ:

Full Fine-tuning:
β”β”€ ν•™μµ νλΌλ―Έν„°: 175,255,168,000 (175B)
β”β”€ GPU λ©”λ¨λ¦¬: ~1.2TB (A100 15μ¥)
β””β”€ μ €μ¥ κ³µκ°„ (νƒμ¤ν¬λ‹Ή): 700GB

LoRA (r=4):
β”β”€ ν•™μµ νλΌλ―Έν„°: 4,718,592 (4.7M)
β”β”€ GPU λ©”λ¨λ¦¬: ~350GB (A100 5μ¥)
β””β”€ μ €μ¥ κ³µκ°„ (νƒμ¤ν¬λ‹Ή): ~35MB

μ κ° ν¨μ¨:
β”β”€ νλΌλ―Έν„°: 37,000λ°° κ°μ†
β”β”€ λ©”λ¨λ¦¬: ~3λ°° κ°μ†
β””β”€ μ €μ¥ κ³µκ°„: 20,000λ°° κ°μ†
```

---

## π§ Ablation Study

### 1. λ­ν¬(r)μ μν–¥

**ν•µμ‹¬ λ°κ²¬: λ­ν¬κ°€ λ†’λ‹¤κ³  λ¬΄μ΅°κ±΄ μΆ‹μ§€ μ•λ‹¤**

```
GPT-3μ—μ„ λ­ν¬ rμ— λ”°λ¥Έ μ„±λ¥ (WikiSQL):

r=1:  73.1%  β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–
r=2:  73.2%  β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–
r=4:  73.4%  β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–
r=8:  73.6%  β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–
r=64: 73.7%  β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–
r=256: 73.5% β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–

β†’ r=4~8μ—μ„ μ΄λ―Έ μ¶©λ¶„ν• μ„±λ¥
β†’ rλ¥Ό λ†’μ—¬λ„ κ°μ„  λ―Έλ―Έ (μλ ΄)
```

**μ™ λ‚®μ€ λ­ν¬λ΅λ„ μ¶©λ¶„ν•κ°€?**
```
κ°€μ„¤: Ξ”Wμ μ‹¤μ  μ •λ³΄λ” λ§¤μ° λ‚®μ€ μ°¨μ›μ— μ§‘μ¤‘λ¨

κ²€μ¦ (SVD λ¶„μ„):
LoRA (r=64)λ΅ ν•™μµν• Ξ”Wλ¥Ό SVDλ΅ λ¶„ν•΄ν•λ©΄:
β”β”€ μƒμ„ 1κ° singular value: μ „μ²΄ λ¶„μ‚°μ 40%
β”β”€ μƒμ„ 4κ° singular value: μ „μ²΄ λ¶„μ‚°μ 75%
β””β”€ μƒμ„ 8κ° singular value: μ „μ²΄ λ¶„μ‚°μ 90%

κ²°λ΅ : μ‹¤μ  μ μ©ν• μ •λ³΄λ” rank ~8 μ΄λ‚΄μ— μ§‘μ¤‘
```

### 2. μ–΄λ–¤ κ°€μ¤‘μΉ ν–‰λ ¬μ— μ μ©ν•  κ²ƒμΈκ°€?

**Transformer 4κ°€μ§€ ν–‰λ ¬μ— λ€ν• μ‹¤ν— (GPT-3, μ΄ νλΌλ―Έν„° 18M κ³ μ •):**

| μ μ© ν–‰λ ¬ | r | μ„±λ¥ (WikiSQL) |
|---------|---|--------------|
| W_q only | 8 | 70.4% |
| W_v only | 8 | 73.0% |
| W_q, W_v | 4 | **73.4%** |
| W_q, W_k, W_v, W_o | 2 | 73.7% |
| W_q, W_k, W_v, W_o, FFN | 1 | 73.5% |

**ν•µμ‹¬ μΈμ‚¬μ΄νΈ:**
- λ™μΌ νλΌλ―Έν„° μμ‚°μ—μ„ **λ” λ§μ€ ν–‰λ ¬μ— λ‚®μ€ λ­ν¬λ΅ μ μ©**ν•λ” κ²ƒμ΄ λ” ν¨κ³Όμ 
- W_qμ™€ W_vλ¥Ό ν•¨κ» μ μ©ν•λ” κ²ƒμ΄ μΆ‹μ€ κΈ°λ³Έκ°’

### 3. Adapterμ™€μ κ³µμ •ν• λΉ„κµ

```
μ¶”λ΅  μ§€μ—° λΉ„κµ (GPT-2 Medium):

λ°©λ²•          | νλΌλ―Έν„° | μ¶”λ΅  μ§€μ—°
-------------|---------|----------
Full FT      | 345M    | κΈ°μ¤€ (1.0x)
Adapter      | 0.37M   | 1.06x  β† 6% λλ¦Ό
Adapter (λ³‘λ ¬)| 0.37M   | 1.03x  β† 3% λλ¦Ό
LoRA         | 0.35M   | 1.00x  β† μ¶”κ°€ μ§€μ—° μ—†μ

GPU λ°°μΉ ν¬κΈ°κ°€ μ‘μ„ λ• Adapter μ§€μ—°μ΄ λ” λ‘λ“λ¬μ§
(μ‹¤μ  μ„λΉ„μ¤ ν™κ²½μ—μ„ λ¬Έμ )
```

---

## π’» μ‹¤μ‚¬μ© μμ‹

### Hugging Face PEFT λΌμ΄λΈλ¬λ¦¬ ν™μ©

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import get_peft_model, LoraConfig, TaskType
import torch

# κΈ°λ³Έ λ¨λΈ λ΅λ“
model_name = "meta-llama/Llama-2-7b-hf"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# LoRA μ„¤μ •
lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=8,                      # λ­ν¬ (λ³΄ν†µ 4~16)
    lora_alpha=16,            # μ¤μΌ€μΌλ§ (λ³΄ν†µ rμ 2λ°°)
    lora_dropout=0.05,        # λ“λ΅­μ•„μ›ƒ
    bias="none",              # bias μ²λ¦¬
    target_modules=[          # LoRA μ μ© λ¨λ“
        "q_proj",
        "v_proj",
        # "k_proj",           # μ„ νƒμ 
        # "o_proj",           # μ„ νƒμ 
    ]
)

# LoRA μ μ©
model = get_peft_model(model, lora_config)

# ν•™μµ κ°€λ¥ν• νλΌλ―Έν„° ν™•μΈ
model.print_trainable_parameters()
# μ¶λ ¥: trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.0622%
```

### νμΈνλ‹ ν•™μµ λ£¨ν”„

```python
from transformers import TrainingArguments, Trainer
from datasets import load_dataset

# λ°μ΄ν„°μ…‹ λ΅λ“ (μ: Alpaca)
dataset = load_dataset("tatsu-lab/alpaca")

def format_prompt(example):
    if example["input"]:
        prompt = f"### Instruction:\n{example['instruction']}\n\n### Input:\n{example['input']}\n\n### Response:\n{example['output']}"
    else:
        prompt = f"### Instruction:\n{example['instruction']}\n\n### Response:\n{example['output']}"
    return {"text": prompt}

dataset = dataset.map(format_prompt)

# ν•™μµ μ„¤μ •
training_args = TrainingArguments(
    output_dir="./lora-finetuned",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,           # LoRAλ” μƒλ€μ μΌλ΅ ν° LR μ‚¬μ© κ°€λ¥
    fp16=True,                    # λ©”λ¨λ¦¬ μ μ•½
    logging_steps=100,
    save_steps=500,
    warmup_ratio=0.03,
    lr_scheduler_type="cosine",
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    tokenizer=tokenizer,
)

# ν•™μµ μ‹μ‘
trainer.train()

# LoRA κ°€μ¤‘μΉ μ €μ¥ (λ§¤μ° μ‘μ€ νμΌ!)
model.save_pretrained("./lora-weights")
# μ €μ¥ ν¬κΈ°: ~35MB (vs μ „μ²΄ λ¨λΈ 14GB)
```

### μ¶”λ΅  (Inference)

```python
from peft import PeftModel
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# λ°©λ²• 1: LoRA κ°€μ¤‘μΉ λ³„λ„ λ΅λ“ (λ©”λ¨λ¦¬ κ³µμ )
base_model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-2-7b-hf",
    torch_dtype=torch.float16,
    device_map="auto"
)
model = PeftModel.from_pretrained(base_model, "./lora-weights")

# λ°©λ²• 2: κ°€μ¤‘μΉ λ³‘ν•© (μ¶”λ΅  μ†λ„ μµμ ν™”)
model = model.merge_and_unload()  # LoRAλ¥Ό κΈ°λ³Έ λ¨λΈμ— λ³‘ν•©
# β†’ μ΄ν›„ μ¶”λ΅ μ€ μμ κΈ°λ³Έ λ¨λΈκ³Ό λ™μΌν• μ†λ„

tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")

def generate_response(instruction: str, max_new_tokens: int = 256) -> str:
    prompt = f"### Instruction:\n{instruction}\n\n### Response:\n"
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response.split("### Response:\n")[-1].strip()

# μ‚¬μ© μμ‹
response = generate_response("νμ΄μ¬μΌλ΅ ν”Όλ³΄λ‚μΉ μμ—΄μ„ μ¶λ ¥ν•λ” ν•¨μλ¥Ό μ‘μ„±ν•΄μ¤")
print(response)
```

### λ‹¤μ¤‘ νƒμ¤ν¬λ¥Ό μ„ν• LoRA μ „ν™

```python
# LoRAμ λ λ‹¤λ¥Έ μ¥μ : νƒμ¤ν¬λ³„ κ°€μ¤‘μΉ μ „ν™μ΄ λ§¤μ° λΉ λ¦„

class MultiTaskLoRAServer:
    def __init__(self, base_model_name: str):
        self.base_model = AutoModelForCausalLM.from_pretrained(
            base_model_name,
            torch_dtype=torch.float16,
            device_map="auto"
        )
        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)
        self.current_lora = None

    def switch_task(self, task_name: str, lora_path: str):
        """νƒμ¤ν¬ μ „ν™: LoRA κ°€μ¤‘μΉλ§ κµμ²΄ (35MB λ΅λ”©)"""
        if self.current_lora:
            self.current_lora.unload()

        self.current_model = PeftModel.from_pretrained(
            self.base_model,
            lora_path,
            adapter_name=task_name
        )
        self.current_lora = task_name
        print(f"νƒμ¤ν¬ '{task_name}'μΌλ΅ μ „ν™ μ™„λ£")

    def generate(self, prompt: str) -> str:
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.current_model.device)
        with torch.no_grad():
            outputs = self.current_model.generate(**inputs, max_new_tokens=256)
        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)

# μ‚¬μ© μμ‹
server = MultiTaskLoRAServer("meta-llama/Llama-2-7b-hf")

# μ½”λ“ μƒμ„± νƒμ¤ν¬
server.switch_task("coding", "./lora-coding-weights")
code = server.generate("Sort a list in Python")

# λ²μ—­ νƒμ¤ν¬
server.switch_task("translation", "./lora-translation-weights")
translation = server.generate("Translate: Hello World")
```

---

## β οΈ ν•κ³„μ  λ° λ―Έλ λ°©ν–¥

### 1. μ–΄λ–¤ λ μ΄μ–΄μ— μ–΄λ–¤ λ­ν¬λ¥Ό μ μ©ν• μ§€ κ²°μ • μ–΄λ ¤μ›€

```
ν„μ¬ λ°©μ‹: λ¨λ“  λ μ΄μ–΄μ— λ™μΌν• r μ μ©
λ¬Έμ : λ μ΄μ–΄λ§λ‹¤ μ¤‘μ”λ„κ°€ λ‹¤λ¥Ό μ μμ

μμ‹:
β”β”€ μ΄κΈ° λ μ΄μ–΄: μΌλ°μ μΈ μ–Έμ–΄ ν¨ν„΄ λ‹΄λ‹Ή
β”β”€ μ¤‘κ°„ λ μ΄μ–΄: λ¬Έλ§¥ μ΄ν•΄ λ‹΄λ‹Ή
β””β”€ ν›„κΈ° λ μ΄μ–΄: νƒμ¤ν¬ νΉν™” ν‘ν„ λ‹΄λ‹Ή

β†’ λ μ΄μ–΄λ³„ μ¤‘μ”λ„μ— λ”°λΌ rμ„ λ‹¤λ¥΄κ² μ„¤μ •ν•λ©΄?
  (μ: AdaLoRA, 2022)
```

### 2. λ°°μΉ μ¶”λ΅  μ‹ λ‹¤μ¤‘ νƒμ¤ν¬ μ²λ¦¬ μ–΄λ ¤μ›€

```
μ„λΉ„μ¤ μ‹λ‚λ¦¬μ¤: λ™μ‹μ— μ—¬λ¬ νƒμ¤ν¬ μ”μ²­ μ²λ¦¬

λ¬Έμ :
β”β”€ λ°°μΉ λ‚΄ μ”μ²­μ΄ μ„λ΅ λ‹¤λ¥Έ νƒμ¤ν¬λ¥Ό μ„ν• κ²ƒμΌ λ•
β”β”€ κ° μ”μ²­λ§λ‹¤ λ‹¤λ¥Έ LoRA κ°€μ¤‘μΉ μ μ©μ΄ ν•„μ”
β””β”€ ν„μ¬ κµ¬ν„μ—μ„ ν¨μ¨μ  μ²λ¦¬ μ–΄λ ¤μ›€

ν•΄κ²°μ±…:
β””β”€ LoRAX (2023): λ°νƒ€μ„μ—μ„ λ°°μΉλ³„ LoRA λ™μ  μ μ©
```

### 3. μ²« λ²μ§Έ ν† ν° μƒμ„±κΉμ§€μ μ§€μ—° (TTFT)

```
μ¶”λ΅  μ‹ κ°€μ¤‘μΉ λ³‘ν•© μ—†μ΄ μ‚¬μ©ν•  κ²½μ°:
β”β”€ Forward pass: Wβ‚€x + BAx (λ‘ λ²μ ν–‰λ ¬ κ³±)
β””β”€ λ³‘ν•© μ—†μ΄ λ™μ  μ¶”λ΅  μ‹ μ•½κ°„μ μ¤λ²„ν—¤λ“

ν•΄κ²°: merge_and_unload()λ΅ μ‚¬μ „ λ³‘ν•©
λ‹¨μ : νƒμ¤ν¬ μ „ν™ μ‹λ§λ‹¤ μ¬λ³‘ν•© ν•„μ”
```

### 4. ν›„μ† λ°μ „ μ—°κµ¬

| λ°©λ²• | κΈ°μ—¬ | μ—°λ„ |
|------|------|------|
| **AdaLoRA** | μ¤‘μ”λ„μ— λ”°λΌ λ­ν¬ λ™μ  μ΅°μ • | 2022 |
| **QLoRA** | 4-bit μ–‘μν™” + LoRAλ΅ 65B λ¨λΈμ„ λ‹¨μΌ GPUμ—μ„ | 2023 |
| **LoRA+** | Aμ™€ Bμ— λ‹¤λ¥Έ ν•™μµλ¥  μ μ© | 2024 |
| **DoRA** | ν¬κΈ°μ™€ λ°©ν–¥ λ¶„λ¦¬ ν•™μµ | 2024 |
| **rsLoRA** | μ¤μΌ€μΌλ§ ν©ν„° κ°μ„  | 2023 |
| **LoftQ** | μ΄κΈ°ν™” λ°©μ‹ κ°μ„  | 2023 |

---

## π“ ν•µμ‹¬ κµν›

1. **Low-rank κ°€μ„¤μ΄ μ‹¤μ λ΅ μ ν¨**: μ μ‘μ— ν•„μ”ν• λ³€ν™”λ” μ €μ°¨μ› κ³µκ°„μ— μ§‘μ¤‘λ¨
2. **μ¶”λ΅  μ§€μ—° μ—†μμ΄ ν•µμ‹¬ μ°¨λ³„μ **: Adapter λ€λΉ„ κ°€μ¥ ν° μ‹¤μ©μ  κ°•μ 
3. **μ μ€ νλΌλ―Έν„°λ΅λ„ μ¶©λ¶„**: r=4~8λ΅ λ€λ¶€λ¶„μ νƒμ¤ν¬μ—μ„ Full FTμ™€ λ™λ“±ν• μ„±λ¥
4. **λ§μ€ ν–‰λ ¬, λ‚®μ€ λ­ν¬κ°€ ν¨κ³Όμ **: λ™μΌ νλΌλ―Έν„° μμ‚°μ—μ„ λ¶„μ‚° μ μ©μ΄ μ λ¦¬
5. **μ΄κΈ°ν™” μ „λµμ΄ μ¤‘μ”**: B=0 μ΄κΈ°ν™”λ΅ μ•μ •μ μΈ νμΈνλ‹ μ‹μ‘μ  ν™•λ³΄

---

## π“– μ°Έκ³  μλ£

- **μ› λ…Όλ¬Έ**: https://arxiv.org/abs/2106.09685
- **κ³µμ‹ μ½”λ“**: https://github.com/microsoft/LoRA
- **Hugging Face PEFT**: https://github.com/huggingface/peft
- **QLoRA λ…Όλ¬Έ**: https://arxiv.org/abs/2305.14314
- **AdaLoRA λ…Όλ¬Έ**: https://arxiv.org/abs/2303.10512

---

**LoRAλ” LLM νμΈνλ‹μ ν„μ‹¤μ  μ¥λ²½μ„ λ‚®μ¶”μ–΄ AI λ―Όμ£Όν™”μ— ν¬κ² κΈ°μ—¬ν• ν•µμ‹¬ κΈ°λ²•μΌλ΅, ν„μ¬ κ±°μ λ¨λ“  μ¤ν”μ†μ¤ LLM νμΈνλ‹μ μ‚¬μ‹¤μƒ ν‘μ¤€(de facto standard)μ΄ λμ—μµλ‹λ‹¤.**
